{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f01c9a0-99e9-476e-8e4c-835faf3cb49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAuCAYAAABeUotNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACXElEQVR4nO2WQUrrUBSG/4ZCoW1iSLVIkdBBAx1kCQEX0ImgoMsQHAbp3IkrcJCZIELpuIXuQ0vNSKOI3CSVSMXj5DWQUmrPI6m8Rz7I4B6Sky83Nzd/gYgI/wDSbwusSy6aNrlo2uSiaZOLps1fi768vKDVamE0GqWoswJi4nkeWZZFkiQRADo8PKTZbMZtw4Yt2m63qVwuk+M4BICazSZdXFxk4ZagQLR+KLm/v4dhGHBdF7quo1Ao4Pz8HI7jwHXdxLm+78P3/Xj89fWF6XQKWZbRaDQgScxVx3mqXq9HmqbFYwB0dXVFAOjt7S1x7v7+PgFYeozHY/aMFjkPFQQBKpVKolYqlQAAYRhCVdW43u/3EzMqhIBpmgAATdN4swmAJVqpVPD+/p6ofXx8AABkWU7UFUWBoiiJ8Rz2awdzezJNE6+vr/A8L649PDxgb28PW1tb7Juz4K4Vy7Lo5OSEfN+Pv/put/vjdUKIeI0KIdhrlC369PRER0dHVKvVaGdnh87Ozujz8/PH66IoItu2ybZtiqKILcrann6T//9fv2ly0bTZiOjz8zMODg6gqio0TYOqqhgOh6weGxE9Pj5GtVrF7e0tZFmGEAI3Nze8JuwNjcnd3R0BoMvLS9J1na6vrwkA1et1Vp/MReeJ6/HxMQ7Y+POHWkxcq8j81c8T1+7uLorFZAYKw3DtPpmLLktccxYT1yoyF12WuABge3ublbgyFzUMA5Zl4fT0FEEQYDKZAAA6nQ6vUUbfUILFxAWABoMBq0eentImF02bXDRtctG0yUXTJhdNm2/tMzRBDgOZWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1x1 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "# Here you import other functions and classes\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import encode_batch, AA_KEYS, BL62_VALUES, BL62FREQ_VALUES, BL50, BL50_VALUES\n",
    "from src.models import NNAlignEFSinglePass\n",
    "from src.datasets import NNAlignDatasetEFSinglePass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac69d6f3-e95e-4f5e-b3f5-cba32ab1494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/mhc1_el_subsample/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0d923-093f-41ef-8f6f-5ec9bbc8ed72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# pseudoseq optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8a7d53-08b9-4d41-ad37-1d957172e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mhc1_el_sub10k/sample_no_u.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f97b864-9bc7-4d21-9fa1-407b657e78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_200k_subsample.csv')\n",
    "df200['len'] = df200['sequence'].apply(len)\n",
    "df500 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_500k_subsample.csv')\n",
    "df500['len'] = df500['sequence'].apply(len)\n",
    "\n",
    "df200['flag'] = df200.apply(lambda x: any([z not in AA_KEYS for z in x['sequence']]), axis=1)\n",
    "df500['flag'] = df500.apply(lambda x: any([z not in AA_KEYS for z in x['sequence']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db317344-a630-4bd5-ad04-c0b7f0675095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>pseudoseq</th>\n",
       "      <th>fold</th>\n",
       "      <th>len</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>IVALILSTK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A68:01</td>\n",
       "      <td>YGLIVASTKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>EENNSFQRL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B44:03</td>\n",
       "      <td>PAEEENQRLSPX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>KMKEALLSIGK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A03:01</td>\n",
       "      <td>MTKKMKIGKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>VVNPKYEGK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A03:01</td>\n",
       "      <td>VTTVVNEGKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>GANSKLTFGKG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B44:03</td>\n",
       "      <td>XYTGANGKGITL</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195692</th>\n",
       "      <td>GRLLIQPGPRF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B27:01</td>\n",
       "      <td>KPYGRLPRFHXX</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195894</th>\n",
       "      <td>YFDLWGRGTLVT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A24:02</td>\n",
       "      <td>XYWYFDLVTVSS</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196815</th>\n",
       "      <td>DGQKLLFARGTML</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B51:01</td>\n",
       "      <td>XFSDGQTMLKVD</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197104</th>\n",
       "      <td>YFDLWGRGTLVT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A24:02</td>\n",
       "      <td>XYWYFDLVTVSS</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197886</th>\n",
       "      <td>RLTDYVAFL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A02:01</td>\n",
       "      <td>QLARLTAFLENX</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sequence  target         HLA     pseudoseq  fold  len   flag\n",
       "635         IVALILSTK     1.0  HLA-A68:01  YGLIVASTKXXX     0    9  False\n",
       "975         EENNSFQRL     1.0  HLA-B44:03  PAEEENQRLSPX     0    9  False\n",
       "1057      KMKEALLSIGK     1.0  HLA-A03:01  MTKKMKIGKXXX     0   11  False\n",
       "2105        VVNPKYEGK     1.0  HLA-A03:01  VTTVVNEGKXXX     0    9  False\n",
       "2336      GANSKLTFGKG     0.0  HLA-B44:03  XYTGANGKGITL     0   11  False\n",
       "...               ...     ...         ...           ...   ...  ...    ...\n",
       "195692    GRLLIQPGPRF     1.0  HLA-B27:01  KPYGRLPRFHXX     4   11  False\n",
       "195894   YFDLWGRGTLVT     0.0  HLA-A24:02  XYWYFDLVTVSS     4   12  False\n",
       "196815  DGQKLLFARGTML     0.0  HLA-B51:01  XFSDGQTMLKVD     4   13  False\n",
       "197104   YFDLWGRGTLVT     0.0  HLA-A24:02  XYWYFDLVTVSS     4   12  False\n",
       "197886      RLTDYVAFL     1.0  HLA-A02:01  QLARLTAFLENX     4    9  False\n",
       "\n",
       "[277 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df200.query('pseudoseq.str.contains(\"X\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "02ced574-f6aa-4b5f-a1b7-5a60e135c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = df200.query('not flag').rename(columns={'pseudoseq':'context'})\n",
    "df500 = df500.query('not flag').rename(columns={'pseudoseq':'context'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a606d6e1-478c-49e9-862e-9772394a1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import PSEUDOSEQDICT\n",
    "df200['pseudoseq'] = df200['HLA'].map(PSEUDOSEQDICT)\n",
    "df500['pseudoseq'] = df500['HLA'].map(PSEUDOSEQDICT)\n",
    "print(df500['pseudoseq'].isna().any())\n",
    "df200.to_csv('../data/mhc1_el_subsample/mhc1_el_200k_subsample.csv', index=False)\n",
    "df500.to_csv('../data/mhc1_el_subsample/mhc1_el_500k_subsample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e9400864-1687-4a55-ba9f-2a2103455f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHC_pseudo.dat              mhc1_el_500k_subsample.csv\n",
      "README                      \u001b[34mmhc1_el_sub10k\u001b[m\u001b[m/\n",
      "mhc1_el_200k_subsample.csv  test_data.csv\n"
     ]
    }
   ],
   "source": [
    "%ls ../data/mhc1_el_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a26ad680-cd75-49b7-8c5a-92198a6f8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for f in glob.glob('../data/mhc1_el_sub10k/*.csv'):\n",
    "    df = pd.read_csv(f)\n",
    "    df.rename(columns = {'pseudoseq':'context'}, inplace=True)\n",
    "    df['pseudoseq'] = df['HLA'].map(PSEUDOSEQDICT)\n",
    "    assert not df['pseudoseq'].isna().any(), f'{f}wtf man,'\n",
    "    df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ae652a00-fc9a-43e4-bcef-0022d2c47c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([df200.query('HLA==\"HLA-A02:01\"').sample(100, random_state=13), df200.query('HLA!=\"HLA-A02:01\"').sample(100, random_state=13)])\n",
    "sample.to_csv('../data/mhc1_el_subsample/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224cff5-c4dd-4f06-a757-7ce634f45100",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# testing on the fly batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "17fc2000-e575-4980-981d-6742ef675a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from src.datasets import NNAlignDatasetEFSinglePass\n",
    "dataset = NNAlignDatasetEFSinglePass(sample, 13, 9, 'BL50LO', pad_scale=-20, add_pseudo_sequence=True, indel=True)\n",
    "loader = dataset.get_dataloader(50, SequentialSampler)\n",
    "for batch_normal in loader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "95cf6827-d3bc-4b12-ade4-12a33fdb2dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 15, 180]),\n",
       " torch.Size([50, 15, 1]),\n",
       " torch.Size([50, 680]),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normal[0].shape, batch_normal[1].shape, batch_normal[2].shape, batch_normal[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e762d50e-71d8-4834-87de-a7a022bd84dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-3., -3., -4., -5., -2., -4., -3., -4., -1.,  0.,  1., -4.,  0.,  8.,\n",
       "          -4., -3., -2.,  1.,  4., -1.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-1., -2., -2., -4., -2.,  0., -2., -3., -1.,  2.,  3., -2.,  7.,  0.,\n",
       "          -3., -2., -1., -1.,  0.,  1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -3.,  0., -1., -3., -2., -3.,  8., -2., -4., -4., -2., -3., -4.,\n",
       "          -2.,  0., -2., -3., -3., -4.],\n",
       "         [-1.,  0.,  0.,  2., -3.,  2.,  6., -3.,  0., -4., -3.,  1., -2., -3.,\n",
       "          -1., -1., -1., -3., -2., -3.],\n",
       "         [-1.,  3.,  0., -1., -3.,  2.,  1., -2.,  0., -3., -3.,  6., -2., -4.,\n",
       "          -1.,  0., -1., -3., -2., -3.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2., -2.,  2.,  8., -4.,  0.,  2., -1., -1., -4., -4., -1., -4., -5.,\n",
       "          -1.,  0., -1., -5., -3., -4.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-2., -3., -4., -4., -2., -2., -3., -4., -3.,  2.,  5., -3.,  3.,  1.,\n",
       "          -4., -3., -1., -2., -1.,  1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2.,  7., -1., -2., -4.,  1.,  0., -3.,  0., -4., -3.,  3., -2., -3.,\n",
       "          -3., -1., -1., -3., -1., -3.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-3., -3., -4., -5., -5., -1., -3., -3., -3., -3., -2., -3., -1.,  1.,\n",
       "          -4., -4., -3., 15.,  2., -3.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2., -3., -4., -4., -2., -2., -3., -4., -3.,  2.,  5., -3.,  3.,  1.,\n",
       "          -4., -3., -1., -2., -1.,  1.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-3., -3., -4., -5., -5., -1., -3., -3., -3., -3., -2., -3., -1.,  1.,\n",
       "          -4., -4., -3., 15.,  2., -3.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.]]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processing import encode\n",
    "encoding = 'BL50LO'\n",
    "pad_scale = -20\n",
    "pseudoseq_tensormap = {k: encode(v, 34, encoding, pad_scale).unsqueeze(0) for k,v in PSEUDOSEQDICT.items()}\n",
    "hlas = sample['HLA'].values\n",
    "idx = 0\n",
    "pseudoseq_tensormap[hlas[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "59ffdccb-b87a-4b08-a076-70381333fae1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.datasets import SuperDataset\n",
    "from src.data_processing import encode_batch, PFR_calculation, FR_lengths, pep_len_1hot, batch_insertion_deletion, batch_indel_mask, PSEUDOSEQDICT\n",
    "\n",
    "class TestDataset(SuperDataset):\n",
    "    \"\"\"\n",
    "    CLASS TO USE\n",
    "    \"\"\"\n",
    "\n",
    "    # @profile\n",
    "    def __init__(self, df: pd.DataFrame, max_len: int, window_size: int, encoding: str = 'onehot',\n",
    "                 seq_col: str = 'sequence', target_col: str = 'target', pad_scale: float = None, indel: bool = False,\n",
    "                 burnin_alphabet: str = 'ILVMFYW', feature_cols: list = ['placeholder'],\n",
    "                 add_pseudo_sequence=False, pseudo_seq_col: str = 'pseudoseq', add_pfr=False, add_fr_len=False,\n",
    "                 add_pep_len=False, add_z=True):\n",
    "        # start = dt.now()\n",
    "        super(TestDataset, self).__init__()\n",
    "        # Encoding stuff\n",
    "        if feature_cols is None:\n",
    "            feature_cols = []\n",
    "        # Filter out sequences longer than max_len\n",
    "        df['len'] = df[seq_col].apply(len)\n",
    "        df = df.query('len<=@max_len')\n",
    "        # Then, if indel is False, filter out sequences shorter than windowsize (ex: 8mers for WS=9)\n",
    "        if not indel:\n",
    "            df = df.query('len>=@window_size')\n",
    "\n",
    "        matrix_dim = 20\n",
    "        # query_time = dt.now()\n",
    "        x = encode_batch(df[seq_col], max_len, encoding, pad_scale)\n",
    "        y = torch.from_numpy(df[target_col].values).float().view(-1, 1)\n",
    "        # encode_time = dt.now()\n",
    "        # Creating the mask to allow selection of kmers without padding\n",
    "        len_mask = torch.from_numpy(df['len'].values)\n",
    "        x_mask = len_mask - window_size\n",
    "        range_tensor = torch.arange(max_len - window_size + 1).unsqueeze(0).repeat(len(x), 1)\n",
    "        # Mask for Kmers + padding\n",
    "        x_mask = (range_tensor <= x_mask.unsqueeze(1)).float().unsqueeze(-1)\n",
    "        # Expand the kmers windows for base sequence without indels\n",
    "        x = x.unfold(1, window_size, 1).transpose(2, 3) \\\n",
    "             .reshape(len(x), max_len - window_size + 1, window_size, matrix_dim)\n",
    "        # Creating indels window and mask \n",
    "        if indel:\n",
    "            x_indel = batch_insertion_deletion(df[seq_col], max_len, encoding, pad_scale, window_size)\n",
    "            # remove padding from indel windows\n",
    "            x_indel = x_indel[:,:,:window_size, :]\n",
    "            indel_mask = batch_indel_mask(len_mask, window_size)\n",
    "            x = torch.cat([x, x_indel], dim=1)\n",
    "            x_mask = torch.cat([x_mask, indel_mask], dim=1)\n",
    "        \n",
    "        # Creating another mask for the burn-in period+bool flag switch\n",
    "        self.burn_in_mask = _get_burnin_mask_batch(df[seq_col].values, max_len, window_size, burnin_alphabet).unsqueeze(\n",
    "            -1)\n",
    "        self.burn_in_flag = False\n",
    "\n",
    "        # Expand and unfold the sub kmers and the target to match the shape ; contiguous to allow for view operations\n",
    "        self.x_tensor = x.flatten(2, 3).contiguous()\n",
    "        self.x_mask = x_mask\n",
    "        \n",
    "        self.pseudoseq_tensormap = {k: encode(v, 34, encoding, pad_scale).unsqueeze(0).flatten(start_dim=1) for k,v in PSEUDOSEQDICT.items()}\n",
    "        # kmer_time = dt.now()\n",
    "        self.y = y.contiguous()\n",
    "        self.x_features = torch.empty((len(x),))\n",
    "        # Add extra features\n",
    "        if len(feature_cols) > 0:\n",
    "            # TODO: When you add more features you need to concatenate to x_pseudosequence and save it to self.x_features\n",
    "            # these are NUMERICAL FEATURES like %Rank, expression, etc. of shape (N, len(feature_cols))\n",
    "            # x_features = torch.from_numpy(df[feature_cols].values).float()\n",
    "\n",
    "            self.extra_features_flag = True\n",
    "        else:\n",
    "            self.extra_features_flag = False\n",
    "\n",
    "        #  TODO dictmap for 9mer look-up and see if how many duplicated and can we save memory\n",
    "        #\n",
    "        if add_pseudo_sequence:\n",
    "            self.hla_tag = df['HLA'].values\n",
    "            self.extra_features_flag = True\n",
    "            # ps_time = dt.now()\n",
    "        if add_pfr:\n",
    "            x_pfr = PFR_calculation(df[seq_col], self.x_mask, max_len, window_size)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_pfr], dim=2)\n",
    "            # pfr_time = dt.now()\n",
    "        if add_fr_len:\n",
    "            x_fr_len = FR_lengths(self.x_mask, max_len, window_size)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_fr_len], dim=2)\n",
    "            # pfr_len_time = dt.now()\n",
    "        if add_pep_len:\n",
    "            x_pep_len = pep_len_1hot(df[seq_col], max_len, window_size, min_length=13, max_length=21)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_pep_len], dim=2)\n",
    "            # peplen_time = dt.now()\n",
    "\n",
    "        # Saving df in case it's needed\n",
    "        self.df = df\n",
    "        self.len = len(x)\n",
    "        self.max_len = max_len\n",
    "        self.seq_col = seq_col\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns the appropriate input tensors (X, ..., y) depending on the bool flags\n",
    "        A bit convoluted return, but basically 4 conditions:\n",
    "            1. No burn-in, no extra features --> returns the normal x_tensor, kmers mask, target\n",
    "            2. Burn-in, no extra features --> returns the normal x_tensor, burn-in mask, target\n",
    "            3. No Burn-in, + extra features --> returns the normal x_tensor, kmers mask, x_features, target\n",
    "            4. Burn-in, + extra features --> returns the normal x_tensor, burn-in mask, x_features, target\n",
    "        :param idx:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.burn_in_flag:\n",
    "            if self.extra_features_flag:\n",
    "                x_pseudoseq = self.pseudoseq_tensormap[self.hlas[idx]]\n",
    "                return self.x_tensor[idx], self.burn_in_mask[idx], x_pseudoseq, self.y[idx]\n",
    "            else:\n",
    "                # 2\n",
    "                return self.x_tensor[idx], self.burn_in_mask[idx], self.y[idx]\n",
    "        else:\n",
    "            if self.extra_features_flag:\n",
    "                # 3\n",
    "                return self.x_tensor[idx], self.x_mask[idx], x_pseudoseq, self.y[idx]\n",
    "            else:\n",
    "                # 1\n",
    "                return self.x_tensor[idx], self.x_mask[idx], self.y[idx]\n",
    "\n",
    "    def burn_in(self, flag):\n",
    "        self.burn_in_flag = flag\n",
    "\n",
    "def _get_burnin_mask_batch(sequences, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_burnin_mask(x, max_len, motif_len, alphabet) for x in sequences])\n",
    "\n",
    "\n",
    "def _get_burnin_mask(seq, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    mask = torch.tensor([x in alphabet for i, x in enumerate(seq) if i < len(seq) - motif_len + 1]).float()\n",
    "    return F.pad(mask, (0, (max_len - motif_len + 1) - len(mask)), 'constant', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "79c639bc-e8db-4938-b871-e7d54fd58ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = TestDataset(sample, 13, 9, 'BL50LO', pad_scale=-20, add_pseudo_sequence=True, indel=True)\n",
    "testloader = dataset.get_dataloader(50, SequentialSampler)\n",
    "for batch in testloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a7ae09da-7523-4a51-8d6f-3337d923ec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch[0]==batch_normal[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "eaace935-6295-4677-86ed-0383ca45d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch[2]==batch_normal[2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "58991f07-1626-4dd3-85d6-4fc4f2601095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 15, 180]),\n",
       " torch.Size([50, 15, 1]),\n",
       " torch.Size([50, 680]),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045d2f3-9d73-4ba3-ba07-adc12b6f2bcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# what the init code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b8f3beb2-aa30-4306-8061-2d5b9a40c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import NNAlignDatasetEFSinglePass, PseudoOTFDataset\n",
    "from src.models import NNAlignEFSinglePass\n",
    "from src.utils import get_class_initcode_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1629d037-631e-435f-956c-4539ca4dba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_len']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'max_len':13}\n",
    "get_class_initcode_keys(PseudoOTFDataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4583e92f-f9a8-4733-a29b-ac00d9a5c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 3\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# stupid init code name changes if we profile it ; Need a UglyWorkAround class to get the same init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f26df464-d32b-4bc8-a4dc-bbf58823186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self',\n",
       " 'df',\n",
       " 'max_len',\n",
       " 'window_size',\n",
       " 'encoding',\n",
       " 'seq_col',\n",
       " 'target_col',\n",
       " 'pad_scale',\n",
       " 'indel',\n",
       " 'burnin_alphabet',\n",
       " 'feature_cols',\n",
       " 'add_pseudo_sequence',\n",
       " 'pseudo_seq_col',\n",
       " 'add_pfr',\n",
       " 'add_fr_len',\n",
       " 'add_pep_len',\n",
       " 'add_z',\n",
       " 'matrix_dim',\n",
       " 'x',\n",
       " 'y',\n",
       " 'len_mask',\n",
       " 'x_mask',\n",
       " 'range_tensor',\n",
       " 'x_indel',\n",
       " 'indel_mask',\n",
       " 'x_pfr',\n",
       " 'x_fr_len',\n",
       " 'x_pep_len')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PseudoOTFDataset.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "173fb13f-18f5-4ff8-8502-d54b6f0134bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('args', 'kwargs', 'prof', 'val')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignDatasetEFSinglePass.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3095cf8d-e92d-41a1-af00-20821f8fc925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x95\\x03\\x97\\x00\\x02\\x00\\x89\\x05\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x02\\x02\\x00\\x02\\x00|\\x02\\x89\\x04\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00i\\x00|\\x01\\xa4\\x01\\x8e\\x01}\\x03\\x02\\x00\\x89\\x06|\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00|\\x03S\\x00'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignDatasetEFSinglePass.__init__.__code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "680e247c-c46e-459a-bc6a-dc5a376f2709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self',\n",
       " 'n_hidden',\n",
       " 'n_hidden_2',\n",
       " 'window_size',\n",
       " 'activation',\n",
       " 'extrafeat_dim',\n",
       " 'batchnorm',\n",
       " 'dropout',\n",
       " 'standardize',\n",
       " 'add_hidden_layer')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignEFSinglePass.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2229599-0dd8-40d7-ba55-7426eaf8e434",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# burn_in mask need to match indel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "96641b69-49e0-4c7a-a017-15a5ef4cefbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARNDCQEGHILKMFPSTWYV'"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(AA_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "282df748-abe2-45ff-86cf-9d1480739cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_burnin_mask_batch(sequences, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_burnin_mask(x, max_len, motif_len, alphabet) for x in sequences])\n",
    "\n",
    "\n",
    "def _get_burnin_mask(seq, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    mask = torch.tensor([x in alphabet for i, x in enumerate(seq) if i < len(seq) - motif_len + 1]).float()\n",
    "    return F.pad(mask, (0, (max_len - motif_len + 1) - len(mask)), 'constant', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "db43ff45-5098-4821-97dd-b11be9b1c01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_burnin_mask_batch(sample['sequence'].head(15), 13, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "08b96f39-8e6c-4411-8766-cc40f31c9c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELEMIKKKHLV'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6a25482b-0a89-4ee4-8ad5-354cc4e6dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QMEARQKECGA'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "04c00d45-5c28-4ea0-beac-016ebfea6a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RQLASEGLPAL'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b8e64c72-907c-4ec8-bfb9-1c87da1f660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FLQLMIDSQ'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "57657e96-b622-4670-afae-6342b6b22a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADNIYIFLEL'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "53508ea8-1586-484d-a1d7-b60c7e3a403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VELEMIKKKHL 11\n",
      "['LEMIKKKHL', 'VEMIKKKHL', 'VEMIKKKHL', 'VELIKKKHL', 'VELEKKKHL', 'VELEMKKHL', 'VELEMIKHL', 'VELEMIKHL', 'VELEMIKKL', 'VELEMIKKK']\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "seq='VELEMIKKKHL'\n",
    "indel_windows = get_indel_windows(seq, 9)\n",
    "indel_burnin_mask = torch.tensor([x[0] in alphabet for x in indel_windows]).float()\n",
    "print(seq, len(seq))\n",
    "print(indel_windows)\n",
    "print(indel_burnin_mask, indel_burnin_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "80f4c1fd-daf5-4a99-9d94-b5189bc19af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_indel_burnin_mask(seq, window_size, alphabet='ILVMFYW'):\n",
    "    indel_windows = get_indel_windows(seq, window_size)\n",
    "    return torch.tensor([x[0] in alphabet for x in indel_windows]).float()\n",
    "\n",
    "def _get_indel_burnin_mask_batch(sequences, window_size, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_indel_burnin_mask(x, window_size, alphabet) for x in sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f43c42fd-590b-4379-ae4b-0987cb81e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_burnin_mask = _get_indel_burnin_mask_batch(sample['sequence'], 9).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2baa9804-6c76-4ad7-89a0-c55a8dcd3b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10, 1])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indel_burnin_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f21b0025-8b0b-44d6-9d26-f3f904b01d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 5, 1])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.burn_in_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ab93a18d-1dc2-49cd-ab76-a05dc1b8d438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 15, 1])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([dataset.burn_in_mask, indel_burnin_mask], dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c8d33-596a-4dcf-8f25-32e833b8aa64",
   "metadata": {},
   "source": [
    "# Optim / vectorize Carlos' code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd6e0c-8ed5-4bfc-b647-3a65c75b8b50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parallelize encode_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51178c14-d122-4335-9827-63b91e24c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import encode\n",
    "\n",
    "def encode_batch(sequences, max_len=None, encoding='onehot', pad_scale=None):\n",
    "    \"\"\"\n",
    "    Encode multiple sequences at once.\n",
    "    \"\"\"\n",
    "    if max_len is None:\n",
    "        max_len = max([len(x) for x in sequences])\n",
    "    # Contiguous to allow for .view operation\n",
    "    return torch.stack([encode(seq, max_len, encoding, pad_scale) for seq in sequences]).contiguous()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fdd8f8-d578-46e2-bc3f-d1eabd357c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_200 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_200k_subsample.csv')\n",
    "sample_500 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_500k_subsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "edd3ba2f-0365-48bd-a6fe-1d0f291a4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "\n",
    "def encode_batch_parallel(sequences, max_len, encoding, pad_scale, n_jobs=1):\n",
    "    if max_len is None:\n",
    "        max_len = max([len(x) for x in sequences])\n",
    "\n",
    "    assert n_jobs!=0, \"n_jobs can't be 0! should be either -1 or >1, or == 1 to run a single process\"\n",
    "    if n_jobs!=1:\n",
    "        wrapper = partial(encode, max_len=max_len, encoding=encoding, pad_scale=pad_scale)\n",
    "        return torch.stack(Parallel(n_jobs=n_jobs)(delayed(wrapper)(seq) for seq in sequences)).contiguous()\n",
    "    else:\n",
    "        return torch.stack([encode(seq, max_len, encoding, pad_scale) for seq in sequences]).contiguous()\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def encode_batch_parallel2(sequences, max_len, encoding, pad_scale, n_jobs=1):\n",
    "    if max_len is None:\n",
    "        max_len = max(len(x) for x in sequences)\n",
    "\n",
    "    if n_jobs != 1:\n",
    "        wrapper = partial(encode, max_len=max_len, encoding=encoding, pad_scale=pad_scale)\n",
    "        with Pool(processes=n_jobs) as pool:\n",
    "            return torch.stack(pool.map(wrapper, sequences)).contiguous()\n",
    "    else:\n",
    "        return torch.stack([encode(seq, max_len, encoding, pad_scale) for seq in sequences]).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "e81e4d92-a93e-4c6e-aa89-2d331eeee2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.755262833001325\n",
      "5.617532249998476\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter as pc\n",
    "max_len = 13\n",
    "encoding = 'BL50LO'\n",
    "pad_scale = -20\n",
    "# 200k \n",
    "start_200 = pc()\n",
    "encode_batch(sample_200['sequence'].values, max_len, encoding, pad_scale)\n",
    "end_200 = pc()\n",
    "print(end_200-start_200)\n",
    "# 500k \n",
    "start_500 = pc()\n",
    "encode_batch(sample_500['sequence'].values, max_len, encoding, pad_scale)\n",
    "end_500 = pc()\n",
    "print(end_500-start_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "4cbfef28-6786-45ea-a507-f8b0f046fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.39354325000022\n",
      "18.800689040996076\n"
     ]
    }
   ],
   "source": [
    "# 200k \n",
    "start_200 = pc()\n",
    "encode_batch_parallel(sample_200['sequence'].values, max_len, encoding, pad_scale, n_jobs=5)\n",
    "end_200 = pc()\n",
    "print(end_200-start_200)\n",
    "# 500k \n",
    "start_500 = pc()\n",
    "encode_batch_parallel(sample_500['sequence'].values, max_len, encoding, pad_scale, n_jobs=5)\n",
    "end_500 = pc()\n",
    "print(end_500-start_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82f205db-0972-4e73-a75c-817b79f816a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.87753145900001\n",
      "38.10106829100005\n"
     ]
    }
   ],
   "source": [
    "# 200k \n",
    "start_200 = pc()\n",
    "encode_batch_parallel2(sample_200['sequence'].values, max_len, encoding, pad_scale, n_jobs=5)\n",
    "end_200 = pc()\n",
    "print(end_200-start_200)\n",
    "# 500k \n",
    "start_500 = pc()\n",
    "encode_batch_parallel2(sample_500['sequence'].values, max_len, encoding, pad_scale, n_jobs=5)\n",
    "end_500 = pc()\n",
    "print(end_500-start_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d556e9d-497d-4891-919f-225ad3b58c33",
   "metadata": {},
   "source": [
    "## vectorize PFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de91eb0-3fdd-4d95-9722-fe1a1d4bc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xxs(df, max_len, encoding, pad_scale, window_size=9):\n",
    "    x = encode_batch(df['sequence'], max_len, encoding, pad_scale)\n",
    "    # Creating the mask to allow selection of kmers without padding\n",
    "    len_mask = torch.from_numpy(df['len'].values)\n",
    "    x_mask = len_mask - window_size\n",
    "    range_tensor = torch.arange(max_len - window_size + 1).unsqueeze(0).repeat(len(x), 1)\n",
    "    # Mask for Kmers + padding\n",
    "    x_mask = (range_tensor <= x_mask.unsqueeze(1)).float().unsqueeze(-1)\n",
    "    # Expand the kmers windows for base sequence without indels\n",
    "    x = x.unfold(1, window_size, 1).transpose(2, 3) \\\n",
    "        .reshape(len(x), max_len - window_size + 1, window_size, 20)\n",
    "    return x, x_mask\n",
    "\n",
    "x_200, mask_200 = get_xxs(sample_200, max_len, encoding, pad_scale, window_size=9)\n",
    "x_500, mask_500 = get_xxs(sample_500, max_len, encoding, pad_scale, window_size=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16e5a4-ad7e-488a-9c72-8d65aef78be3",
   "metadata": {},
   "source": [
    "### step by step deconstruct / redo pfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e569eabf-8012-4259-af5f-730bb15689b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def PFR_calculation_vect(df_seq, all_xmask, max_len, window_size=9):\n",
    "    data = encode_batch(df_seq, max_len, 'BL62FREQ', None)  # Assuming encode_batch is a function to process df_seq\n",
    "    batch_size, seq_len, aa_dim = data.shape\n",
    "\n",
    "    # Previous PFR mask definition\n",
    "    PFR_mask_before = 3 * torch.ones((1, seq_len - window_size + 1, 1))\n",
    "    PFR_mask_before[:, :3, 0] = torch.tensor([0, 1, 2], dtype=torch.float32)  # First three elements to 1 and 2\n",
    "\n",
    "    # After PFR mask definition (according to their x_mask)\n",
    "    PFR_mask_after = all_xmask * 3\n",
    "\n",
    "    # Modification of the previous values before 0 (only if zero exists)\n",
    "    zero_indices = torch.where(PFR_mask_after == 0)\n",
    "    zero_index = zero_indices[0][0] if zero_indices[0].numel() > 0 else -1\n",
    "\n",
    "    if zero_index != -1:\n",
    "        zero_index = zero_index.item()\n",
    "        PFR_mask_after[zero_index - 3:zero_index] = torch.tensor([2, 1, 0])[:zero_index]\n",
    "\n",
    "    # Create indices for the sliding window\n",
    "    indices = torch.arange(0, seq_len - window_size + 1).view(1, -1) + torch.arange(0, window_size).view(-1, 1)\n",
    "\n",
    "    # Expand dimensions for broadcasting\n",
    "    indices = indices.unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "    # Extract WS-mers from the input sequence\n",
    "    windows = data[:, indices]\n",
    "\n",
    "    # Compute PFR tensors\n",
    "    prev_pfr = torch.sum(windows[:, :, :int(PFR_mask_before[0])], dim=2, keepdim=True) / 3\n",
    "    after_pfr = torch.sum(windows[:, :, window_size:int(window_size + PFR_mask_after)], dim=2, keepdim=True) / 3\n",
    "\n",
    "    # Concatenate PFR tensors along the second axis\n",
    "    all_pfr = torch.cat((prev_pfr, after_pfr), dim=2)\n",
    "\n",
    "    return all_pfr.flatten(start_dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33a691e1-fa61-45f4-bda5-f3d4269bcb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_200, mask_200 = get_xxs(sample_200, max_len, encoding, pad_scale, window_size=9)\n",
    "x_500, mask_500 = get_xxs(sample_500, max_len, encoding, pad_scale, window_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "b629b7a6-d6f0-4868-81ce-aa22ce0d7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=13\n",
    "window_size=5\n",
    "\n",
    "sample = sample_200.groupby('len', group_keys=False).apply(lambda x: x.sample(1, random_state=13))\n",
    "data = encode_batch(sample['sequence'], max_len, 'BL62FREQ', None)\n",
    "batch_size, seq_len, aa_dim = data.shape\n",
    "_, mask_10  = get_xxs(sample, max_len, encoding, pad_scale, window_size)\n",
    "pfr10 = PFR_calculation(sample['sequence'].values, mask_10, max_len, window_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "4e2cdbea-1fe7-41a8-8760-8a0ab8ec44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 13, 20]), torch.Size([6, 9, 1]), torch.Size([6, 5, 40]))"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, mask_10.shape, pfr10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1717c116-4754-4091-84e4-97ce13028624",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///////\n",
      "['EKIIGAGKPWHKN' 13]\n",
      "\n",
      "##############\n",
      "\n",
      "PFR BEFORE\n",
      " tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [3.]]) \n",
      "PFR AFTER\n",
      " tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.]])\n",
      "tensor([], dtype=torch.int64) 0\n",
      "\n",
      "##############\n",
      "\n",
      "tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "j = 5\n",
    "print('///////')\n",
    "print(sample.iloc[j][['sequence', 'len']].values)\n",
    "print('\\n##############\\n')\n",
    "seq = data[j, :]\n",
    "PFR_mask_before = 3 * torch.ones((max_len - window_size + 1, 1))\n",
    "PFR_mask_before[:3, 0] = torch.tensor([0, 1, 2], dtype=torch.float32)  # First three elements to 1 and 2\n",
    "# After PFR mask definition (according to their x_mask)\n",
    "PFR_mask_after = torch.clone(mask_10[j]) * 3\n",
    "print('PFR BEFORE\\n',PFR_mask_before, '\\nPFR AFTER\\n', PFR_mask_after)\n",
    "zero_indices = torch.where(PFR_mask_after == 0)[0]\n",
    "print(zero_indices, zero_indices.numel())\n",
    "print('\\n##############\\n')\n",
    "if zero_indices.numel() > 0:  # Check if there are any zero indices\n",
    "    zero_index = zero_indices[0]  # Get the first zero index\n",
    "    PFR_mask_after[zero_index - 3] = 2 if zero_index >= 3 else PFR_mask_after[zero_index - 3]\n",
    "    PFR_mask_after[zero_index - 2] = 1 if zero_index >= 2 else PFR_mask_after[zero_index - 2]\n",
    "    PFR_mask_after[zero_index - 1] = 0 if zero_index >= 1 else PFR_mask_after[zero_index - 1]\n",
    "print(PFR_mask_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "37d5fa0e-37dc-480d-ad8b-7bbaf6deee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 5, 1]), torch.Size([6, 5, 1]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFR_mask_after.shape, PFR_mask_before.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c42cb67b-7d73-4d64-b598-4641ce14a32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>len</th>\n",
       "      <th>flag</th>\n",
       "      <th>pseudoseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30867</th>\n",
       "      <td>RVIPRWNV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C06:02</td>\n",
       "      <td>QRGRVIWNVSHL</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>YDSGYREKYRQADVNKLYLWYDSYTWAEWAYTWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116342</th>\n",
       "      <td>EALEDPSPE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A31:01</td>\n",
       "      <td>LTMEALSPELME</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>YTAMYQENVAHIDVDTLYIMYQDYTWAVLAYTWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110070</th>\n",
       "      <td>MTFSGLNRGF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B57:01</td>\n",
       "      <td>RLMMTFRGFAYA</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAMYGENMASTYENIAYIVYDSYTWAVLAYLWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161107</th>\n",
       "      <td>NLLSSRQVMNT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C17:01</td>\n",
       "      <td>VVLNLLMNTHFN</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAGYREKYRQADVNKLYIRYNFYSLAELAYEWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57799</th>\n",
       "      <td>MWKAQGDQGLER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C06:02</td>\n",
       "      <td>LWLMWKLERRID</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>YDSGYREKYRQADVNKLYLWYDSYTWAEWAYTWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198561</th>\n",
       "      <td>EKIIGAGKPWHKN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C08:02</td>\n",
       "      <td>YAAEKIHKNCFR</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAGYREKYRQTDVSNLYLRYNFYTWAERAYTWY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sequence  target         HLA       context  fold  len   flag  \\\n",
       "30867        RVIPRWNV     0.0  HLA-C06:02  QRGRVIWNVSHL     0    8  False   \n",
       "116342      EALEDPSPE     0.0  HLA-A31:01  LTMEALSPELME     2    9  False   \n",
       "110070     MTFSGLNRGF     0.0  HLA-B57:01  RLMMTFRGFAYA     2   10  False   \n",
       "161107    NLLSSRQVMNT     0.0  HLA-C17:01  VVLNLLMNTHFN     4   11  False   \n",
       "57799    MWKAQGDQGLER     0.0  HLA-C06:02  LWLMWKLERRID     1   12  False   \n",
       "198561  EKIIGAGKPWHKN     0.0  HLA-C08:02  YAAEKIHKNCFR     4   13  False   \n",
       "\n",
       "                                 pseudoseq  \n",
       "30867   YDSGYREKYRQADVNKLYLWYDSYTWAEWAYTWY  \n",
       "116342  YTAMYQENVAHIDVDTLYIMYQDYTWAVLAYTWY  \n",
       "110070  YYAMYGENMASTYENIAYIVYDSYTWAVLAYLWY  \n",
       "161107  YYAGYREKYRQADVNKLYIRYNFYSLAELAYEWY  \n",
       "57799   YDSGYREKYRQADVNKLYLWYDSYTWAEWAYTWY  \n",
       "198561  YYAGYREKYRQTDVSNLYLRYNFYTWAERAYTWY  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequences = sample['sequence'].values\n",
    "random_seqs = sample_200.sample(100)\n",
    "\n",
    "max_len = 13\n",
    "window_size = 9\n",
    "display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "09065b7f-f4b5-46b4-8d7e-d69ac3c54e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
       "         [0, 1, 2, 3, 3, 3, 3, 3, 3]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [2, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [3, 2, 2, 2, 2, 2, 1, 0, 0],\n",
       "         [3, 3, 3, 3, 3, 3, 2, 1, 0]]))"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFR_mask_before, PFR_mask_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6dfa8f1e-092e-4dd9-bb48-7437be5ed1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfrs = PFR_calculation(sequences, mask_10, 13, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ab400eec-e788-4858-a3fb-826c04dd5dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 40])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e114ce-fe7b-4dec-943f-42fcc37d4f6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "219a57c2-f003-421a-9dae-6b2dc57b023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfr_mask_after_single(l, max_len, window_size):\n",
    "    n_windows = max_len-window_size+1\n",
    "    n_3 = l - window_size - 2\n",
    "    n_2 = 1 if n_3>=0 else max(n_3+1, -1)\n",
    "    n_1 = 1 if n_2>=0 else max(n_2+1, -1)\n",
    "    out = torch.cat([torch.full((max(n_3,0),),3), torch.full((max(n_2,0),), 2), torch.full((max(n_1,0),), 1)])\n",
    "    return F.pad(out, (0, n_windows-len(out)), value=0)\n",
    "\n",
    "def batch_pfr_mask_indices(lens, max_len, window_size):\n",
    "    mask = torch.stack([pfr_mask_after_single(l, max_len, window_size) for l in lens])\n",
    "    indices = torch.stack([(torch.arange(0, n_windows)+window_size-1).repeat(len(mask),1).T, (torch.arange(0, n_windows)+window_size-1+mask).T]).T\n",
    "    return mask, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "97fade19-dc50-4a50-8cd5-82e672531ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.96152345900191\n"
     ]
    }
   ],
   "source": [
    "start_500k_mask = pc()\n",
    "mask2, indices2 = batch_pfr_mask_indices(torch.randint(low=8,high=14, size=(500000,)), max_len, window_size)\n",
    "end_500k_mask = pc()\n",
    "print(end_500k_mask - start_500k_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "dc586929-77cf-4d1a-8678-176d6ff0cee5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "window_size = 9\n",
    "max_len = 13 \n",
    "\n",
    "\n",
    "n_windows = max_len - window_size + 1\n",
    "n_3 = len_tensor - window_size - 2\n",
    "n_2 = torch.where(n_3 >= 0, 1, torch.tensor([-1]))\n",
    "n_1 = torch.where(n_2 >= 0, 1, torch.tensor([-1]))\n",
    "max_n_3 = torch.max(torch.tensor([0]), n_3)\n",
    "max_n_2 = torch.max(torch.tensor([0]), n_2)\n",
    "max_n_1 = torch.max(torch.tensor([0]), n_1)\n",
    "\n",
    "out = torch.zeros((len_tensor.shape[0], n_windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "3505f8dd-76f1-4aa8-9a2a-d3d7a512009b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3, -2, -1,  0,  1,  2]) tensor([-1, -1, -1,  1,  1,  1]) tensor([-1, -1, -1,  1,  1,  1])\n",
      "tensor([0, 0, 0, 0, 1, 2]) tensor([0, 0, 0, 1, 1, 1]) tensor([0, 0, 0, 1, 1, 1])\n",
      "tensor([-1, -1, -1, -1,  1,  2]) tensor([-1, -1, -1,  0,  2,  3]) tensor([-1, -1, -1,  1,  3,  4])\n"
     ]
    }
   ],
   "source": [
    "print(n_3, n_2, n_1)\n",
    "print(max_n_3, max_n_2, max_n_1)\n",
    "idx_3 = torch.where(n_3>0, max_n_3, -1)\n",
    "idx_2 = torch.where(n_2>0, idx_3 + 1, -1)\n",
    "idx_1 = torch.where(n_1>0, idx_2 + 1, -1)\n",
    "print(idx_3, idx_2, idx_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "e8175d4c-7b85-4e94-b36e-a77b9cbe6f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 9, 2])"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "381c8228-c1b8-4e3a-a034-ef1dd8b306ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 1, 2, 3, 3, 3, 3, 3, 3],\n",
      "        [0, 1, 2, 3, 3, 3, 3, 3, 3]]) \n",
      " (tensor([[3, 2, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [3, 3, 2, 1, 0, 0, 0, 0, 0],\n",
      "        [3, 3, 3, 2, 1, 0, 0, 0, 0],\n",
      "        [3, 3, 3, 3, 2, 1, 0, 0, 0],\n",
      "        [3, 3, 3, 3, 3, 2, 1, 0, 0],\n",
      "        [3, 3, 3, 3, 3, 3, 2, 1, 0]]), tensor([[[ 4,  7],\n",
      "         [ 5,  7],\n",
      "         [ 6,  7],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 4,  7],\n",
      "         [ 5,  8],\n",
      "         [ 6,  8],\n",
      "         [ 7,  8],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 4,  7],\n",
      "         [ 5,  8],\n",
      "         [ 6,  9],\n",
      "         [ 7,  9],\n",
      "         [ 8,  9],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 4,  7],\n",
      "         [ 5,  8],\n",
      "         [ 6,  9],\n",
      "         [ 7, 10],\n",
      "         [ 8, 10],\n",
      "         [ 9, 10],\n",
      "         [10, 10],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 4,  7],\n",
      "         [ 5,  8],\n",
      "         [ 6,  9],\n",
      "         [ 7, 10],\n",
      "         [ 8, 11],\n",
      "         [ 9, 11],\n",
      "         [10, 11],\n",
      "         [11, 11],\n",
      "         [12, 12]],\n",
      "\n",
      "        [[ 4,  7],\n",
      "         [ 5,  8],\n",
      "         [ 6,  9],\n",
      "         [ 7, 10],\n",
      "         [ 8, 11],\n",
      "         [ 9, 12],\n",
      "         [10, 12],\n",
      "         [11, 12],\n",
      "         [12, 12]]])) \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[779], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m seq \u001b[38;5;241m=\u001b[39m data[j]\n\u001b[1;32m     15\u001b[0m mask_before \u001b[38;5;241m=\u001b[39m PFR_mask_before[j]\n\u001b[0;32m---> 16\u001b[0m mask_after \u001b[38;5;241m=\u001b[39m \u001b[43mPFR_mask_after\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# use these indices to slice somehow \u001b[39;00m\n\u001b[1;32m     18\u001b[0m after_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n_windows)\u001b[38;5;241m+\u001b[39mwindow_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n_windows)\u001b[38;5;241m+\u001b[39mwindow_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mmask_after])\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "max_len, window_size = 13, 5\n",
    "n_windows = max_len - window_size + 1 \n",
    "# vectorizing ; \n",
    "data = encode_batch(sequences, max_len, 'BL62FREQ', None) # shape (N, 13, 20)\n",
    "len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "PFR_mask_before = torch.full((len(data), max_len-window_size+1), 3)\n",
    "PFR_mask_before[:, :3] = torch.tensor([0,1,2], dtype=torch.float32)\n",
    "# Mask before is ALWAYS the same.\n",
    "PFR_mask_after = pfr_mask_after_batch(len_tensor, max_len, window_size)\n",
    "print(PFR_mask_before,'\\n', PFR_mask_after,'\\n')\n",
    "\n",
    "j = 2\n",
    "n_windows = max_len-window_size+1\n",
    "seq = data[j]\n",
    "mask_before = PFR_mask_before[j]\n",
    "mask_after = PFR_mask_after[j]\n",
    "# use these indices to slice somehow \n",
    "# SCRATCHPAD\n",
    "after_indices = torch.stack([torch.arange(0, n_windows)+window_size-1, torch.arange(0, n_windows)+window_size-1+mask_after]).T\n",
    "before_indices = torch.stack([torch.arange(0, n_windows)-mask_before, torch.arange(0, n_windows)]).T\n",
    "print(before_indices,'\\n', after_indices )\n",
    "# indices should be used as a [start:end] slicing ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbd416-7995-440b-ac0d-f2279468c89c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Slicing gathering?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1c20553-dcf2-46cd-95ff-9300f7db778a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import torch.nn.functional as F\n",
    "def get_pfr_indices_after(l, max_len, window_size):\n",
    "    n_windows = max_len-window_size+1\n",
    "    n_3 = l - window_size - 2\n",
    "    n_2 = 1 if n_3>=0 else max(n_3+1, -1)\n",
    "    n_1 = 1 if n_2>=0 else max(n_2+1, -1)\n",
    "    mask = torch.cat([torch.full((max(n_3,0),),3), torch.full((max(n_2,0),), 2), torch.full((max(n_1,0),), 1)])\n",
    "    index = \n",
    "    return F.pad(out, (0, n_windows-len(out)), value=0)\n",
    "\n",
    "def batch_pfr_mask_indices(lens, max_len, window_size):\n",
    "    mask = torch.stack([pfr_mask_after_single(l, max_len, window_size) for l in lens])\n",
    "    indices = torch.stack([(torch.arange(0, n_windows)+window_size-1).repeat(len(mask),1).T, (torch.arange(0, n_windows)+window_size-1+mask).T]).T\n",
    "    return mask, indices\n",
    "\n",
    "# Almost there!!\n",
    "def mask_from_index(index_tensor):\n",
    "    N, S, _ = index_tensor.shape  # Batch size, number of sequences, 2 (for start and end indices)\n",
    "\n",
    "    # Create a range tensor of shape [1, 1, max_len] for broadcasting\n",
    "    range_tensor = torch.arange(max_len).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Expand before_indices for start and end to match the shape for broadcasting\n",
    "    start_indices = index_tensor[:,:,0].unsqueeze(2)  # Shape: [N, S, 1]\n",
    "    end_indices = index_tensor[:,:,1].unsqueeze(2)  # Shape: [N, S, 1], +1 to include the end index in the range\n",
    "    \n",
    "    # Create the binary mask\n",
    "    mask = (range_tensor >= start_indices) & (range_tensor < end_indices)  # Shape: [N, S, max_len]\n",
    "    \n",
    "    return mask.int()\n",
    "    \n",
    "max_len, window_size = 13, 5\n",
    "\n",
    "# What the fuck at no point do I ever need the mask if I use index\n",
    "n_windows = max_len - window_size + 1 \n",
    "# vectorizing ; \n",
    "data = encode_batch(sequences, max_len, 'BL62FREQ', None) # shape (N, 13, 20)\n",
    "len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "PFR_mask_before = torch.full((len(data), max_len-window_size+1), 3)\n",
    "PFR_mask_before[:, :3] = torch.tensor([0,1,2], dtype=torch.float32)\n",
    "# Mask before is ALWAYS the same.\n",
    "before_indices = torch.stack([torch.arange(0, n_windows)-mask_before, torch.arange(0, n_windows)]).T.repeat(len(data), 1, 1)\n",
    "PFR_mask_after, after_indices = batch_pfr_mask_indices(len_tensor, max_len, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "d07606fa-054d-4874-bade-2a4a703aad2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000, 0.7500, 0.2500],\n",
       "         [0.5000, 0.5000, 0.6667, 0.3333],\n",
       "         [0.6667, 0.3333, 0.5000, 0.5000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000],\n",
       "         [0.8333, 0.1667, 0.0000, 1.0000],\n",
       "         [0.8571, 0.1429, 0.0000, 1.0000],\n",
       "         [0.8750, 0.1250, 0.0000, 1.0000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8000, 0.2000],\n",
       "         [0.5000, 0.5000, 0.7500, 0.2500],\n",
       "         [0.6667, 0.3333, 0.6667, 0.3333],\n",
       "         [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000],\n",
       "         [0.8333, 0.1667, 0.0000, 1.0000],\n",
       "         [0.8571, 0.1429, 0.0000, 1.0000],\n",
       "         [0.8750, 0.1250, 0.0000, 1.0000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8333, 0.1667],\n",
       "         [0.5000, 0.5000, 0.8000, 0.2000],\n",
       "         [0.6667, 0.3333, 0.7500, 0.2500],\n",
       "         [0.7500, 0.2500, 0.6667, 0.3333],\n",
       "         [0.8000, 0.2000, 0.5000, 0.5000],\n",
       "         [0.8333, 0.1667, 0.0000, 1.0000],\n",
       "         [0.8571, 0.1429, 0.0000, 1.0000],\n",
       "         [0.8750, 0.1250, 0.0000, 1.0000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8571, 0.1429],\n",
       "         [0.5000, 0.5000, 0.8333, 0.1667],\n",
       "         [0.6667, 0.3333, 0.8000, 0.2000],\n",
       "         [0.7500, 0.2500, 0.7500, 0.2500],\n",
       "         [0.8000, 0.2000, 0.6667, 0.3333],\n",
       "         [0.8333, 0.1667, 0.5000, 0.5000],\n",
       "         [0.8571, 0.1429, 0.0000, 1.0000],\n",
       "         [0.8750, 0.1250, 0.0000, 1.0000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8750, 0.1250],\n",
       "         [0.5000, 0.5000, 0.8571, 0.1429],\n",
       "         [0.6667, 0.3333, 0.8333, 0.1667],\n",
       "         [0.7500, 0.2500, 0.8000, 0.2000],\n",
       "         [0.8000, 0.2000, 0.7500, 0.2500],\n",
       "         [0.8333, 0.1667, 0.6667, 0.3333],\n",
       "         [0.8571, 0.1429, 0.5000, 0.5000],\n",
       "         [0.8750, 0.1250, 0.0000, 1.0000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8889, 0.1111],\n",
       "         [0.5000, 0.5000, 0.8750, 0.1250],\n",
       "         [0.6667, 0.3333, 0.8571, 0.1429],\n",
       "         [0.7500, 0.2500, 0.8333, 0.1667],\n",
       "         [0.8000, 0.2000, 0.8000, 0.2000],\n",
       "         [0.8333, 0.1667, 0.7500, 0.2500],\n",
       "         [0.8571, 0.1429, 0.6667, 0.3333],\n",
       "         [0.8750, 0.1250, 0.5000, 0.5000],\n",
       "         [0.8889, 0.1111, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processing import FR_lengths\n",
    "\n",
    "FR_lengths(mask_10, 13, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "731ab14e-ec6c-4157-9b19-0a2e72e47763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pfr_indices_after(10, 13, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "79a205c8-efaf-4022-a6d6-f843035944bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=13\n",
    "window_size=5\n",
    "n_windows=max_len-window_size+1\n",
    "mask = pfr_mask_after_single(13, 13, 5)\n",
    "index=torch.stack([torch.arange(0, n_windows)+window_size, torch.arange(0, n_windows)+window_size+mask]).T\n",
    "mask_from_index(torch.stack([index,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "38caf929-2b72-4886-8b27-1612ad1dc655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pfr_indices_after(l, max_len, window_size):\n",
    "    n_windows = max_len-window_size+1\n",
    "    n_3 = l - window_size - 2\n",
    "    n_2 = 1 if n_3>=0 else max(n_3+1, -1)\n",
    "    n_1 = 1 if n_2>=0 else max(n_2+1, -1)\n",
    "    mask = torch.cat([torch.full((max(n_3,0),),3), torch.full((max(n_2,0),), 2), torch.full((max(n_1,0),), 1)])\n",
    "    mask = F.pad(mask, (0, n_windows-len(mask)), value=0)\n",
    "    return torch.stack([torch.arange(0, n_windows)+window_size, torch.arange(0, n_windows)+window_size+mask]).T\n",
    "\n",
    "def get_pfr_indices_after_batch(lengths, max_len, window_size):\n",
    "    return torch.stack([get_pfr_indices_after(l, max_len, window_size) for l in lengths])\n",
    "    \n",
    "def mask_from_index(index_tensor):\n",
    "    N, S, _ = index_tensor.shape  # Batch size, number of sequences, 2 (for start and end indices)\n",
    "\n",
    "    # Create a range tensor of shape [1, 1, max_len] for broadcasting\n",
    "    range_tensor = torch.arange(max_len).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Expand before_indices for start and end to match the shape for broadcasting\n",
    "    start_indices = index_tensor[:,:,0].unsqueeze(2)  # Shape: [N, S, 1]\n",
    "    end_indices = index_tensor[:,:,1].unsqueeze(2)  # Shape: [N, S, 1], +1 to include the end index in the range\n",
    "    \n",
    "    # Create the binary mask\n",
    "    mask = (range_tensor >= start_indices) & (range_tensor < end_indices)  # Shape: [N, S, max_len]\n",
    "    \n",
    "    return mask.int()\n",
    "\n",
    "    \n",
    "max_len, window_size = 13, 9\n",
    "\n",
    "# What the fuck at no point do I ever need the mask if I use index\n",
    "n_windows = max_len - window_size + 1 \n",
    "# vectorizing ; \n",
    "data = encode_batch(sequences, max_len, 'BL62FREQ', None) # shape (N, 13, 20)\n",
    "len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "mask_before = torch.full((max_len-window_size+1, ), 3)\n",
    "mask_before[:3] = torch.tensor([0,1,2], dtype=torch.float32)\n",
    "# Mask before is ALWAYS the same.\n",
    "before_indices = torch.stack([torch.arange(0, n_windows)-mask_before, torch.arange(0, n_windows)]).T.repeat(len(data), 1, 1)\n",
    "after_indices = get_pfr_indices_after_batch(len_tensor, max_len, window_size)\n",
    "before_mask = mask_from_index(before_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "after_mask = mask_from_index(after_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "# Create the repeat vector to mask and compute the results\n",
    "repeats = data.unsqueeze(1).repeat(1, n_windows, 1, 1)\n",
    "(repeats[0, 0, 0, :] == repeats[0, 2, 0, :]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "6c0b00d8-cfc3-43cd-a746-0a40d121732d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 9, 13, 20]),\n",
       " torch.Size([6, 9, 13, 20]),\n",
       " torch.Size([6, 9, 13, 20]))"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeats.shape, after_mask.shape, before_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "64f4029b-13ea-480a-8876-5f94ab013862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5, 40])"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=(repeats * after_mask).mean(dim=2)\n",
    "b=(repeats * before_mask).mean(dim=2)\n",
    "\n",
    "torch.cat([a,b], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065328ae-53ec-49ed-bd89-ca8dc3d38f84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pfr_values(sequences, max_len, window_size):\n",
    "    # Get the true lengths of each sequence to create the masks\n",
    "    len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "    n_windows = max_len-window_size+1\n",
    "    # Get the data vector to repeat and mask to compute PFR\n",
    "    blosum_freq = encode_batch(sequences, max_len, 'BL62FREQ', None)\n",
    "    # Get the repeated blosum_freq vector (creating N_windows copies along dim=1)\n",
    "    repeats = blosum_freq.unsqueeze(1).repeat(1, n_windows, 1, 1)\n",
    "    # The before mask is the same no matter the length so create it and just repeat it to get the indices\n",
    "    before_mask = torch.full((n_windows, ), 3)\n",
    "    before_mask[:3] = torch.tensor([0,1,2], dtype=torch.float32)\n",
    "    before_indices = torch.stack([torch.arange(0, n_windows)-mask_before, torch.arange(0, n_windows)]).T.repeat(len(data), 1, 1)\n",
    "    # Use my custom function and length tensor to create the after_indices\n",
    "    after_indices = get_pfr_indices_after_batch(len_tensor, max_len, window_size)\n",
    "    # Create the mask of shape (N, n_windows, max_len, 20) to use on the repeated freq_data and broadcast it 20 times along amino acid dimension\n",
    "    before_mask = mask_from_index(before_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "    after_mask = mask_from_index(after_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "    # Take dim=2 because that's the sequence length dimension \n",
    "    pfr_before = (repeats*before_mask).mean(dim=2)\n",
    "    pfr_after = (repeats*after_mask).mean(dim=2)\n",
    "    return torch.cat([pfr_before, pfr_after], dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3930425-8a3d-4de0-8568-3d0c10378540",
   "metadata": {},
   "source": [
    "### final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04431856-9d62-44d1-9bb7-df1c0668514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pfr_indices_after(l, max_len, window_size):\n",
    "    n_windows = max_len-window_size+1\n",
    "    n_3 = l - window_size - 2\n",
    "    n_2 = 1 if n_3>=0 else max(n_3+1, -1)\n",
    "    n_1 = 1 if n_2>=0 else max(n_2+1, -1)\n",
    "    mask = torch.cat([torch.full((max(n_3,0),),3), torch.full((max(n_2,0),), 2), torch.full((max(n_1,0),), 1)])\n",
    "    mask = F.pad(mask, (0, n_windows-len(mask)), value=0)\n",
    "    return torch.stack([torch.arange(0, n_windows)+window_size, torch.arange(0, n_windows)+window_size+mask]).T\n",
    "\n",
    "def get_pfr_indices_after_batch(lengths, max_len, window_size):\n",
    "    return torch.stack([get_pfr_indices_after(l, max_len, window_size) for l in lengths])\n",
    "    \n",
    "def mask_from_index(index_tensor):\n",
    "    N, S, _ = index_tensor.shape  # Batch size, number of sequences, 2 (for start and end indices)\n",
    "\n",
    "    # Create a range tensor of shape [1, 1, max_len] for broadcasting\n",
    "    range_tensor = torch.arange(max_len).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Expand before_indices for start and end to match the shape for broadcasting\n",
    "    start_indices = index_tensor[:,:,0].unsqueeze(2)  # Shape: [N, S, 1]\n",
    "    end_indices = index_tensor[:,:,1].unsqueeze(2)  # Shape: [N, S, 1], +1 to include the end index in the range\n",
    "    \n",
    "    # Create the binary mask\n",
    "    mask = (range_tensor >= start_indices) & (range_tensor < end_indices)  # Shape: [N, S, max_len]\n",
    "    \n",
    "    return mask.int()\n",
    "\n",
    "def get_pfr_values(sequences, max_len, window_size):\n",
    "    # Get the true lengths of each sequence to create the masks\n",
    "    len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "    n_windows = max_len-window_size+1\n",
    "    # Get the data vector to repeat and mask to compute PFR\n",
    "    blosum_freq = encode_batch(sequences, max_len, 'BL62FREQ', None)\n",
    "    # Get the repeated blosum_freq vector (creating N_windows copies along dim=1)\n",
    "    repeats = blosum_freq.unsqueeze(1).repeat(1, n_windows, 1, 1)\n",
    "    # The before mask is the same no matter the length so create it and just repeat it to get the indices\n",
    "    before_mask = torch.full((n_windows, ), 3)\n",
    "    before_mask[:3] = torch.tensor([0,1,2], dtype=torch.float32)\n",
    "    before_indices = torch.stack([torch.arange(0, n_windows)-before_mask, torch.arange(0, n_windows)]).T.repeat(len(sequences), 1, 1)\n",
    "    # Use my custom function and length tensor to create the after_indices\n",
    "    after_indices = get_pfr_indices_after_batch(len_tensor, max_len, window_size)\n",
    "    # Create the mask of shape (N, n_windows, max_len, 20) to use on the repeated freq_data and broadcast it 20 times along amino acid dimension\n",
    "    before_mask = mask_from_index(before_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "    after_mask = mask_from_index(after_indices).unsqueeze(-1).repeat(1,1,1,20)\n",
    "    # Take dim=2 because that's the sequence length dimension \n",
    "    pfr_before = (repeats*before_mask).mean(dim=2)\n",
    "    pfr_after = (repeats*after_mask).mean(dim=2)\n",
    "    return torch.cat([pfr_before, pfr_after], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae5ffaf7-a4af-4532-a423-deb409a1c1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 40])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size=9\n",
    "max_len=13\n",
    "\n",
    "get_pfr_values(sample.sample(5)['sequence'].values, max_len, window_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecfb3f51-ffea-42ea-a0c3-a94c1b61998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sample = sample.groupby('len', group_keys=False).apply(lambda x: x.sample(1))\n",
    "pfrs = get_pfr_values(len_sample['sequence'].values, max_len, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cfae3c2-aa52-4c5c-be38-a4ba681b1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing time\n",
    "from time import perf_counter as pc\n",
    "from src.data_processing import PFR_calculation\n",
    "def get_xxs(df, max_len, encoding, pad_scale, window_size=9):\n",
    "    x = encode_batch(df['sequence'], max_len, encoding, pad_scale)\n",
    "    # Creating the mask to allow selection of kmers without padding\n",
    "    len_mask = torch.from_numpy(df['len'].values)\n",
    "    x_mask = len_mask - window_size\n",
    "    range_tensor = torch.arange(max_len - window_size + 1).unsqueeze(0).repeat(len(x), 1)\n",
    "    # Mask for Kmers + padding\n",
    "    x_mask = (range_tensor <= x_mask.unsqueeze(1)).float().unsqueeze(-1)\n",
    "    # Expand the kmers windows for base sequence without indels\n",
    "    x = x.unfold(1, window_size, 1).transpose(2, 3) \\\n",
    "        .reshape(len(x), max_len - window_size + 1, window_size, 20)\n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eb675d9-c2d6-439c-ab66-59ead56fa7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample5m = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_5M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac659bb9-d064-4a3c-b557-8ed07341f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample5m['len']=sample5m.sequence.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9996e2b-d9bb-42a4-9ada-811e2ba0b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlos PFR:  365.34099750000314\n"
     ]
    }
   ],
   "source": [
    "max_len = 13\n",
    "window_size = 9\n",
    "encoding = 'BL50LO'\n",
    "pad_scale = -20\n",
    "# Old (Carlos) way of doing PFR with double loop\n",
    "start_old = pc()\n",
    "x, x_mask = get_xxs(sample5m, max_len, encoding, pad_scale, window_size)\n",
    "_ = PFR_calculation(sample5m['sequence'].values, x_mask, max_len, window_size)\n",
    "end_old = pc()\n",
    "print('Carlos PFR: ', end_old-start_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd7e6f35-b693-4cdc-a504-cb20df568e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500000, 5, 40])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3d877a0-c4d7-43f0-b0df-d2a713420c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New PFR:  197.2465631659943\n"
     ]
    }
   ],
   "source": [
    "# New (vectorized) way of doing PFR\n",
    "start_new = pc()\n",
    "get_pfr_values(sample5m['sequence'].values, max_len, window_size)\n",
    "end_new = pc()\n",
    "print('New PFR: ', end_new-start_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6757789-cd2a-4f95-9f05-ac763c00b674",
   "metadata": {},
   "source": [
    "## Vectorize FR lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72ea074c-fa0a-4b80-b89a-aee9e2d07306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mask = get_xxs(sample, 13, 'BL50LO', -20, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "099a512d-effe-4c1d-8c1e-574eeaf80100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import FR_lengths\n",
    "from src.datasets import NNAlignDatasetEFSinglePass\n",
    "max_len, window_size = 13, 9\n",
    "\n",
    "ordered_sample = sample_200.groupby('len', group_keys=False).apply(lambda x: x.sample(1))\n",
    "ds = NNAlignDatasetEFSinglePass(ordered_sample, max_len, window_size, 'BL50LO', add_fr_len=True)\n",
    "fr_len = FR_lengths(ds.x_mask, max_len, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b675bac-917c-439f-b48e-2caab272b3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 5, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3932123-b1aa-46e7-a43e-843aa7be586e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.x_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e88a880d-83db-4896-ad53-fdf74dcd59b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.5       , 0.66666667, 0.75      , 0.8       ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5) / (np.arange(5)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0b74f78b-23c7-42f7-a2c3-9a505f6cf015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "322efec1-28e3-4ab1-9aec-d4b0bdc1583f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.5000, 0.5000, 0.0000, 1.0000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.5000, 0.5000, 0.0000, 1.0000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.0000, 1.0000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.6667, 0.3333],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.7500, 0.2500],\n",
       "         [0.5000, 0.5000, 0.6667, 0.3333],\n",
       "         [0.6667, 0.3333, 0.5000, 0.5000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8000, 0.2000],\n",
       "         [0.5000, 0.5000, 0.7500, 0.2500],\n",
       "         [0.6667, 0.3333, 0.6667, 0.3333],\n",
       "         [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_tensor = torch.tensor([8,9,10,11,12,13])\n",
    "get_fr_lengths(len_tensor, 13, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cde5cec-4777-45b2-b189-c151691be6a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.5000, 0.5000, 0.0000, 1.0000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.0000, 1.0000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.6667, 0.3333],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.6667, 0.3333, 0.0000, 1.0000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.7500, 0.2500],\n",
       "         [0.5000, 0.5000, 0.6667, 0.3333],\n",
       "         [0.6667, 0.3333, 0.5000, 0.5000],\n",
       "         [0.7500, 0.2500, 0.0000, 1.0000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]],\n",
       "\n",
       "        [[0.0000, 1.0000, 0.8000, 0.2000],\n",
       "         [0.5000, 0.5000, 0.7500, 0.2500],\n",
       "         [0.6667, 0.3333, 0.6667, 0.3333],\n",
       "         [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "         [0.8000, 0.2000, 0.0000, 1.0000]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50bf7ff4-eda0-4667-873b-201c70c54c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import get_pfr_indices_after_batch, mask_from_index\n",
    "def get_pfr_values(sequences, max_len, window_size):\n",
    "    # Get the true lengths of each sequence to create the masks\n",
    "    len_tensor = torch.tensor([len(x) for x in sequences])\n",
    "    n_windows = max_len - window_size + 1\n",
    "    # Get the data vector to repeat and mask to compute PFR\n",
    "    blosum_freq = encode_batch(sequences, max_len, 'BL62FREQ', None)\n",
    "    # Get the repeated blosum_freq vector (creating N_windows copies along dim=1)\n",
    "    repeats = blosum_freq.unsqueeze(1).repeat(1, n_windows, 1, 1)\n",
    "    # The before mask is the same no matter the length so create it and just repeat it to get the indices\n",
    "    before_mask = torch.full((n_windows,), 3)\n",
    "    before_mask[:3] = torch.tensor([0, 1, 2], dtype=torch.float32)\n",
    "    before_indices = torch.stack([torch.arange(0, n_windows) - before_mask, torch.arange(0, n_windows)]).T.repeat(\n",
    "        len(sequences), 1, 1)\n",
    "    # Use my custom function and length tensor to create the after_indices\n",
    "    after_indices = get_pfr_indices_after_batch(len_tensor, max_len, window_size)\n",
    "    # Create the mask of shape (N, n_windows, max_len, 20) to use on the repeated freq_data and broadcast it 20 times along amino acid dimension\n",
    "    before_mask = mask_from_index(before_indices, max_len).unsqueeze(-1).repeat(1, 1, 1, 20)\n",
    "    after_mask = mask_from_index(after_indices, max_len).unsqueeze(-1).repeat(1, 1, 1, 20)\n",
    "    # Take dim=2 because that's the sequence length dimension\n",
    "    pfr_before = (repeats * before_mask).mean(dim=2)\n",
    "    pfr_after = (repeats * after_mask).mean(dim=2)\n",
    "    return torch.cat([pfr_before, pfr_after], dim=2), after_indices, after_mask\n",
    "\n",
    "pfr, after_indices, after_mask = get_pfr_values(sample['sequence'], max_len, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89baccd3-a9d6-49b9-a7d0-c290ea6e249c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9, 10],\n",
       "         [10, 10],\n",
       "         [11, 11],\n",
       "         [12, 12],\n",
       "         [13, 13]],\n",
       "\n",
       "        [[ 9, 12],\n",
       "         [10, 12],\n",
       "         [11, 12],\n",
       "         [12, 12],\n",
       "         [13, 13]],\n",
       "\n",
       "        [[ 9, 12],\n",
       "         [10, 12],\n",
       "         [11, 12],\n",
       "         [12, 12],\n",
       "         [13, 13]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9, 11],\n",
       "         [10, 11],\n",
       "         [11, 11],\n",
       "         [12, 12],\n",
       "         [13, 13]],\n",
       "\n",
       "        [[ 9, 12],\n",
       "         [10, 13],\n",
       "         [11, 13],\n",
       "         [12, 13],\n",
       "         [13, 13]],\n",
       "\n",
       "        [[ 9,  9],\n",
       "         [10, 10],\n",
       "         [11, 11],\n",
       "         [12, 12],\n",
       "         [13, 13]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1d9b6-497c-4a24-8fb3-05bd98a37b0a",
   "metadata": {},
   "source": [
    "## vectorize pep len 1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1a4e398d-599c-46fb-9c23-85af444c39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159, 14, 1])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignDatasetEFSinglePass(sample, 12, 5, 'BL50LO', indel=True).x_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "745ecaaf-c11a-4f37-93f0-9930d52f1a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=13\n",
    "window_size=9\n",
    "max_len - window_size + 1, window_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5cb82169-0284-4261-b9e6-cb7169a118b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 - 9 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "54210d85-fff3-48f1-9ce5-37bec4c3c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pep_len_onehot(len_tensor, max_len, window_size, min_clip, max_clip, indel=False):\n",
    "    # Scaling the lengths and clipping to set to min/max clip values\n",
    "    scaled_lengths = (len_tensor - min_clip + 1).clip(min=0, max=max_clip-min_clip+1)\n",
    "    # getting onehot encoding and repeating to accomodate n_windows\n",
    "    n_windows = max_len+2 if indel else max_len - window_size + 1 \n",
    "    return F.one_hot(scaled_lengths, num_classes = max_clip-min_clip+2).unsqueeze(1).repeat(1, n_windows, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3962c26b-6f46-4a21-b550-1067073fbda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_tensor = torch.tensor([5, 7, 7, 8, 9, 10, 11, 12, 13, 14, 14, 15, 30, 42])\n",
    "min_clip = 8\n",
    "max_clip = 13\n",
    "(len_tensor - min_clip + 1).clip(min=0, max = max_clip - min_clip + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ceb099-c978-4b32-ad45-79171d75c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing import pep_len_1hot\n",
    "pep_len_1hot("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "354d8096-5334-4a28-93bb-a2db0f223bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 5, 7])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pep_len_onehot(len_tensor, max_len, window_size, min_clip, max_clip).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e7048382-a34e-443f-bd69-642f21c6e143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_clip - min_clip + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9ae54383-d443-46b8-b47e-331f4963d06a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sequences = [i for i in range(12,22)] * 1000000\n",
    "pep_len_1hot(sample_sequences, max_len, window_size, min_length = 13, max_length = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "68211f8d-dd1c-45ce-aa0c-2c37263615dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12-8+ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "922d516d-9f0d-4930-af97-f0553c181b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_tensor.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "783c7fde-d3bd-4db1-bab0-076dc56a5650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2, 5, 40])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = torch.zeros((100, 5, 40))\n",
    "torch.stack([rd, torch.zeros(rd.shape[0], 5, rd.shape[-1])], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5876683e-ea8f-4268-80e1-c30108add80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[273], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "043ff241-32b0-44ab-9e5b-6509380e7c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>len</th>\n",
       "      <th>flag</th>\n",
       "      <th>pseudoseq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82466</th>\n",
       "      <td>KITLQDKQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B40:01</td>\n",
       "      <td>ATSKITDKQNMV</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>YHTKYREISTNTYESNLYLRYNYYSLAVLAYEWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145094</th>\n",
       "      <td>SRLNNIVNR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B27:05</td>\n",
       "      <td>PQASRLVNRSMT</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>YHTEYREICAKTDEDTLYLNYHDYTWAVLAYEWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72590</th>\n",
       "      <td>GCCHVRTGTI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C12:03</td>\n",
       "      <td>RCCGCCGTIILG</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAGYREKYRQADVSNLYLWYDSYTWAEWAYTWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67714</th>\n",
       "      <td>KVRESERAFTY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B57:01</td>\n",
       "      <td>LSQKVRFTYSIV</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAMYGENMASTYENIAYIVYDSYTWAVLAYLWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124546</th>\n",
       "      <td>VTLVKDFHVDTI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "      <td>DPGVTLDTILFP</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193573</th>\n",
       "      <td>TGPPPVNKPEMRL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-C08:02</td>\n",
       "      <td>PVSTGPMRLLCP</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>YYAGYREKYRQTDVSNLYLRYNFYTWAERAYTWY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sequence  target         HLA       context  fold  len   flag  \\\n",
       "82466        KITLQDKQ     0.0  HLA-B40:01  ATSKITDKQNMV     2    8  False   \n",
       "145094      SRLNNIVNR     1.0  HLA-B27:05  PQASRLVNRSMT     3    9  False   \n",
       "72590      GCCHVRTGTI     0.0  HLA-C12:03  RCCGCCGTIILG     1   10  False   \n",
       "67714     KVRESERAFTY     1.0  HLA-B57:01  LSQKVRFTYSIV     1   11  False   \n",
       "124546   VTLVKDFHVDTI     0.0  HLA-A01:01  DPGVTLDTILFP     3   12  False   \n",
       "193573  TGPPPVNKPEMRL     0.0  HLA-C08:02  PVSTGPMRLLCP     4   13  False   \n",
       "\n",
       "                                 pseudoseq  \n",
       "82466   YHTKYREISTNTYESNLYLRYNYYSLAVLAYEWY  \n",
       "145094  YHTEYREICAKTDEDTLYLNYHDYTWAVLAYEWY  \n",
       "72590   YYAGYREKYRQADVSNLYLWYDSYTWAEWAYTWY  \n",
       "67714   YYAMYGENMASTYENIAYIVYDSYTWAVLAYLWY  \n",
       "124546  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  \n",
       "193573  YYAGYREKYRQTDVSNLYLRYNFYTWAERAYTWY  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c7218-78c6-4031-a060-affec49e1a05",
   "metadata": {},
   "source": [
    "## Fixing PFR / FR len in case of Indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "83b9c777-591a-44f9-8249-fa3c119f5305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 4])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_len.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5568927e-f07e-4130-a625-c537b2fbc7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 15, 40])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([pfr, torch.zeros(len(pfr), window_size+1, 40)], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b294fed3-b8b9-4959-b7d1-392e9fce5f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 5, 4])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fr_lengths(len_tensor, max_len, window_size).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
