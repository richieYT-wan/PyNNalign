{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f01c9a0-99e9-476e-8e4c-835faf3cb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEsAAABWCAYAAACHBmuvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAABuvAAAbrwFeGpEcAAAEdElEQVR4nO2azStsfxzHX2PGnSLytPA8kzykRkixtFEof4GEIqUoGzsrayvGZjILG3lYiJKFIiULC5ntlIdhPOVhUGaI4bfQmXvdezHf2/ccnV/f12oWn+Z9evU9M99zvm/L6+vrK4q4SPjuCzATSpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYASpYAhsmanp6mrKyMubk5oyKlY9PjSyORCBMTEywtLREMBrHb7UQiET2iDEX6ygqHw3R0dOB2uwkGg+Tm5nJ/f080GgVgdXVVdqRhSJc1PDyMz+ejrKyM1tZWgsEgv56JrK6usrm5KTvWEKTKOjw8ZHFxEYvFwvX1NZOTkwAMDAyQl5cXmxsbG5MZaxhSZS0sLBCNRikuLubi4oKqqipmZ2fp7e19N7e9vc3JyYnMaEOQKmtnZweA6upqPB4PMzMzuFyudzNpaWkAbG1tyYw2BKmyAoEAABUVFdTX1/91RpN1cHAgM9oQpMq6uroCICMj48OZpKQkAEKhkMxoQ5Aq6+HhAYAfP358OGOz2d7NmgmpsqxWKwAWi+Xr4ATzPWlJvWLtFnt8fPxw5vn5GQC73S4z2hCkykpPTwfg5ubmw5lwOAxAZmamzGhDkCqrqKgIgGAw+OGM9sPudDplRhuCVFmVlZXAz/3W37i9vQXe9mJmQ6qspqYm4G3Dube39+FcbW0t+fn5MqMNQaosp9NJS0sL0WiU/v7+2CYVfv5WAX88/pgFi+yaZCgUor29Hb/fj9VqpbS0lLu7O46PjwFoaGhgfHxcZqRhSJcFb6vI6/WyvLzM0dERNpsNl8tFW1sbjY2NsuMMQxdZ/1fMt43+RpQsAZQsAZQsAZQsAZQsAZQsAZQsAUwpKxKJMDY2RlNTEy6Xi7q6Orq6ulhfX9e1U6FL10FPwuEwnZ2d+Hw+EhMTKSkp4ebmho2NDTY2NkhMTNQt23QrS6sHlJeXs7Kywvz8PGtra/T09ADw9PSkW7apVpZWD0hISGBkZIScnBweHx/xeDx4vV7d8021srR6QFVVFcXFxQQCARobG3G73QB0d3fHZj87B/hXTCVLe11dU1MDwNnZGaenp7FOxeDgYOw4bn9/X3q+qW5D7c1rYWEhANnZ2Xg8nndVAavVSjQa5fLyUnq+qWT9Xg9wOBw4HI53M9rh7a+vsWVhqtswnnqAdhqux7+iqWSJ1APimRHFVLLiqQdob8n12JyaSlY89YCXlxcAkpOTpeebSlY89QCtFZ2VlSU931SyvqoHnJ+fx2QVFBRIzzeVrK/qAVNTU7HPn7UP/xVTyfqsHrCwsMDExISu+abalAIMDQ3h9/vx+/00Nzf/UQ9ITU3l7u5Ol2xTrSx4+0ecmZmhr68Pp9PJ7u4uoVCI2tpaRkdHSUlJ0S1bHd8LYLqV9Z0oWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQIoWQL8B+8Ugojtu0b4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1.8x1.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "# Here you import other functions and classes\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import encode_batch, AA_KEYS, BL62_VALUES, BL62FREQ_VALUES, HLAS, BL50, BL50_VALUES\n",
    "from src.models import NNAlignEFSinglePass\n",
    "from src.datasets import NNAlignDatasetEFSinglePass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8a7d53-08b9-4d41-ad37-1d957172e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mhc1_el_sub10k/sample_no_u.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f97b864-9bc7-4d21-9fa1-407b657e78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_200k_subsample.csv')\n",
    "df200['len'] = df200['sequence'].apply(len)\n",
    "df500 = pd.read_csv('../data/mhc1_el_subsample/mhc1_el_500k_subsample.csv')\n",
    "df500['len'] = df500['sequence'].apply(len)\n",
    "\n",
    "df200['flag'] = df200.apply(lambda x: any([z not in AA_KEYS for z in x['sequence']]), axis=1)\n",
    "df500['flag'] = df500.apply(lambda x: any([z not in AA_KEYS for z in x['sequence']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db317344-a630-4bd5-ad04-c0b7f0675095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>pseudoseq</th>\n",
       "      <th>fold</th>\n",
       "      <th>len</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>IVALILSTK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A68:01</td>\n",
       "      <td>YGLIVASTKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>EENNSFQRL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B44:03</td>\n",
       "      <td>PAEEENQRLSPX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>KMKEALLSIGK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A03:01</td>\n",
       "      <td>MTKKMKIGKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>VVNPKYEGK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A03:01</td>\n",
       "      <td>VTTVVNEGKXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>GANSKLTFGKG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B44:03</td>\n",
       "      <td>XYTGANGKGITL</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195692</th>\n",
       "      <td>GRLLIQPGPRF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-B27:01</td>\n",
       "      <td>KPYGRLPRFHXX</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195894</th>\n",
       "      <td>YFDLWGRGTLVT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A24:02</td>\n",
       "      <td>XYWYFDLVTVSS</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196815</th>\n",
       "      <td>DGQKLLFARGTML</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B51:01</td>\n",
       "      <td>XFSDGQTMLKVD</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197104</th>\n",
       "      <td>YFDLWGRGTLVT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A24:02</td>\n",
       "      <td>XYWYFDLVTVSS</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197886</th>\n",
       "      <td>RLTDYVAFL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HLA-A02:01</td>\n",
       "      <td>QLARLTAFLENX</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sequence  target         HLA     pseudoseq  fold  len   flag\n",
       "635         IVALILSTK     1.0  HLA-A68:01  YGLIVASTKXXX     0    9  False\n",
       "975         EENNSFQRL     1.0  HLA-B44:03  PAEEENQRLSPX     0    9  False\n",
       "1057      KMKEALLSIGK     1.0  HLA-A03:01  MTKKMKIGKXXX     0   11  False\n",
       "2105        VVNPKYEGK     1.0  HLA-A03:01  VTTVVNEGKXXX     0    9  False\n",
       "2336      GANSKLTFGKG     0.0  HLA-B44:03  XYTGANGKGITL     0   11  False\n",
       "...               ...     ...         ...           ...   ...  ...    ...\n",
       "195692    GRLLIQPGPRF     1.0  HLA-B27:01  KPYGRLPRFHXX     4   11  False\n",
       "195894   YFDLWGRGTLVT     0.0  HLA-A24:02  XYWYFDLVTVSS     4   12  False\n",
       "196815  DGQKLLFARGTML     0.0  HLA-B51:01  XFSDGQTMLKVD     4   13  False\n",
       "197104   YFDLWGRGTLVT     0.0  HLA-A24:02  XYWYFDLVTVSS     4   12  False\n",
       "197886      RLTDYVAFL     1.0  HLA-A02:01  QLARLTAFLENX     4    9  False\n",
       "\n",
       "[277 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df200.query('pseudoseq.str.contains(\"X\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "02ced574-f6aa-4b5f-a1b7-5a60e135c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = df200.query('not flag').rename(columns={'pseudoseq':'context'})\n",
    "df500 = df500.query('not flag').rename(columns={'pseudoseq':'context'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a606d6e1-478c-49e9-862e-9772394a1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import PSEUDOSEQDICT\n",
    "df200['pseudoseq'] = df200['HLA'].map(PSEUDOSEQDICT)\n",
    "df500['pseudoseq'] = df500['HLA'].map(PSEUDOSEQDICT)\n",
    "print(df500['pseudoseq'].isna().any())\n",
    "df200.to_csv('../data/mhc1_el_subsample/mhc1_el_200k_subsample.csv', index=False)\n",
    "df500.to_csv('../data/mhc1_el_subsample/mhc1_el_500k_subsample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e9400864-1687-4a55-ba9f-2a2103455f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHC_pseudo.dat              mhc1_el_500k_subsample.csv\n",
      "README                      \u001b[34mmhc1_el_sub10k\u001b[m\u001b[m/\n",
      "mhc1_el_200k_subsample.csv  test_data.csv\n"
     ]
    }
   ],
   "source": [
    "%ls ../data/mhc1_el_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a26ad680-cd75-49b7-8c5a-92198a6f8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for f in glob.glob('../data/mhc1_el_sub10k/*.csv'):\n",
    "    df = pd.read_csv(f)\n",
    "    df.rename(columns = {'pseudoseq':'context'}, inplace=True)\n",
    "    df['pseudoseq'] = df['HLA'].map(PSEUDOSEQDICT)\n",
    "    assert not df['pseudoseq'].isna().any(), f'{f}wtf man,'\n",
    "    df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "ae652a00-fc9a-43e4-bcef-0022d2c47c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([df200.query('HLA==\"HLA-A02:01\"').sample(100, random_state=13), df200.query('HLA!=\"HLA-A02:01\"').sample(100, random_state=13)])\n",
    "sample.to_csv('../data/mhc1_el_subsample/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224cff5-c4dd-4f06-a757-7ce634f45100",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# testing on the fly batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "17fc2000-e575-4980-981d-6742ef675a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler\n",
    "from src.datasets import NNAlignDatasetEFSinglePass\n",
    "dataset = NNAlignDatasetEFSinglePass(sample, 13, 9, 'BL50LO', pad_scale=-20, add_pseudo_sequence=True, indel=True)\n",
    "loader = dataset.get_dataloader(50, SequentialSampler)\n",
    "for batch_normal in loader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "95cf6827-d3bc-4b12-ade4-12a33fdb2dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 15, 180]),\n",
       " torch.Size([50, 15, 1]),\n",
       " torch.Size([50, 680]),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_normal[0].shape, batch_normal[1].shape, batch_normal[2].shape, batch_normal[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e762d50e-71d8-4834-87de-a7a022bd84dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-3., -3., -4., -5., -2., -4., -3., -4., -1.,  0.,  1., -4.,  0.,  8.,\n",
       "          -4., -3., -2.,  1.,  4., -1.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-1., -2., -2., -4., -2.,  0., -2., -3., -1.,  2.,  3., -2.,  7.,  0.,\n",
       "          -3., -2., -1., -1.,  0.,  1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -3.,  0., -1., -3., -2., -3.,  8., -2., -4., -4., -2., -3., -4.,\n",
       "          -2.,  0., -2., -3., -3., -4.],\n",
       "         [-1.,  0.,  0.,  2., -3.,  2.,  6., -3.,  0., -4., -3.,  1., -2., -3.,\n",
       "          -1., -1., -1., -3., -2., -3.],\n",
       "         [-1.,  3.,  0., -1., -3.,  2.,  1., -2.,  0., -3., -3.,  6., -2., -4.,\n",
       "          -1.,  0., -1., -3., -2., -3.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2., -2.,  2.,  8., -4.,  0.,  2., -1., -1., -4., -4., -1., -4., -5.,\n",
       "          -1.,  0., -1., -5., -3., -4.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-2., -3., -4., -4., -2., -2., -3., -4., -3.,  2.,  5., -3.,  3.,  1.,\n",
       "          -4., -3., -1., -2., -1.,  1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2.,  7., -1., -2., -4.,  1.,  0., -3.,  0., -4., -3.,  3., -2., -3.,\n",
       "          -3., -1., -1., -3., -1., -3.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-2.,  0.,  1., -1., -3.,  1.,  0., -2., 10., -4., -3.,  0., -1., -1.,\n",
       "          -2., -1., -2., -3.,  2., -4.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-3., -3., -4., -5., -5., -1., -3., -3., -3., -3., -2., -3., -1.,  1.,\n",
       "          -4., -4., -3., 15.,  2., -3.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [ 0., -3., -3., -4., -1., -3., -3., -4., -4.,  4.,  1., -3.,  1., -1.,\n",
       "          -3., -2.,  0., -3., -1.,  5.],\n",
       "         [-2., -3., -4., -4., -2., -2., -3., -4., -3.,  2.,  5., -3.,  3.,  1.,\n",
       "          -4., -3., -1., -2., -1.,  1.],\n",
       "         [ 5., -2., -1., -2., -1., -1., -1.,  0., -2., -1., -2., -1., -1., -3.,\n",
       "          -1.,  1.,  0., -3., -2.,  0.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.],\n",
       "         [ 0., -1.,  0., -1., -1., -1., -1., -2., -2., -1., -1., -1., -1., -2.,\n",
       "          -1.,  2.,  5., -3., -2.,  0.],\n",
       "         [-3., -3., -4., -5., -5., -1., -3., -3., -3., -3., -2., -3., -1.,  1.,\n",
       "          -4., -4., -3., 15.,  2., -3.],\n",
       "         [-2., -1., -2., -3., -3., -1., -2., -3.,  2., -1., -1., -2.,  0.,  4.,\n",
       "          -3., -2., -2.,  2.,  8., -1.]]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processing import encode\n",
    "encoding = 'BL50LO'\n",
    "pad_scale = -20\n",
    "pseudoseq_tensormap = {k: encode(v, 34, encoding, pad_scale).unsqueeze(0) for k,v in PSEUDOSEQDICT.items()}\n",
    "hlas = sample['HLA'].values\n",
    "idx = 0\n",
    "pseudoseq_tensormap[hlas[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "59ffdccb-b87a-4b08-a076-70381333fae1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.datasets import SuperDataset\n",
    "from src.data_processing import encode_batch, PFR_calculation, FR_lengths, pep_len_1hot, batch_insertion_deletion, batch_indel_mask, PSEUDOSEQDICT\n",
    "\n",
    "class TestDataset(SuperDataset):\n",
    "    \"\"\"\n",
    "    CLASS TO USE\n",
    "    \"\"\"\n",
    "\n",
    "    # @profile\n",
    "    def __init__(self, df: pd.DataFrame, max_len: int, window_size: int, encoding: str = 'onehot',\n",
    "                 seq_col: str = 'sequence', target_col: str = 'target', pad_scale: float = None, indel: bool = False,\n",
    "                 burnin_alphabet: str = 'ILVMFYW', feature_cols: list = ['placeholder'],\n",
    "                 add_pseudo_sequence=False, pseudo_seq_col: str = 'pseudoseq', add_pfr=False, add_fr_len=False,\n",
    "                 add_pep_len=False, add_z=True):\n",
    "        # start = dt.now()\n",
    "        super(TestDataset, self).__init__()\n",
    "        # Encoding stuff\n",
    "        if feature_cols is None:\n",
    "            feature_cols = []\n",
    "        # Filter out sequences longer than max_len\n",
    "        df['len'] = df[seq_col].apply(len)\n",
    "        df = df.query('len<=@max_len')\n",
    "        # Then, if indel is False, filter out sequences shorter than windowsize (ex: 8mers for WS=9)\n",
    "        if not indel:\n",
    "            df = df.query('len>=@window_size')\n",
    "\n",
    "        matrix_dim = 20\n",
    "        # query_time = dt.now()\n",
    "        x = encode_batch(df[seq_col], max_len, encoding, pad_scale)\n",
    "        y = torch.from_numpy(df[target_col].values).float().view(-1, 1)\n",
    "        # encode_time = dt.now()\n",
    "        # Creating the mask to allow selection of kmers without padding\n",
    "        len_mask = torch.from_numpy(df['len'].values)\n",
    "        x_mask = len_mask - window_size\n",
    "        range_tensor = torch.arange(max_len - window_size + 1).unsqueeze(0).repeat(len(x), 1)\n",
    "        # Mask for Kmers + padding\n",
    "        x_mask = (range_tensor <= x_mask.unsqueeze(1)).float().unsqueeze(-1)\n",
    "        # Expand the kmers windows for base sequence without indels\n",
    "        x = x.unfold(1, window_size, 1).transpose(2, 3) \\\n",
    "             .reshape(len(x), max_len - window_size + 1, window_size, matrix_dim)\n",
    "        # Creating indels window and mask \n",
    "        if indel:\n",
    "            x_indel = batch_insertion_deletion(df[seq_col], max_len, encoding, pad_scale, window_size)\n",
    "            # remove padding from indel windows\n",
    "            x_indel = x_indel[:,:,:window_size, :]\n",
    "            indel_mask = batch_indel_mask(len_mask, window_size)\n",
    "            x = torch.cat([x, x_indel], dim=1)\n",
    "            x_mask = torch.cat([x_mask, indel_mask], dim=1)\n",
    "        \n",
    "        # Creating another mask for the burn-in period+bool flag switch\n",
    "        self.burn_in_mask = _get_burnin_mask_batch(df[seq_col].values, max_len, window_size, burnin_alphabet).unsqueeze(\n",
    "            -1)\n",
    "        self.burn_in_flag = False\n",
    "\n",
    "        # Expand and unfold the sub kmers and the target to match the shape ; contiguous to allow for view operations\n",
    "        self.x_tensor = x.flatten(2, 3).contiguous()\n",
    "        self.x_mask = x_mask\n",
    "        \n",
    "        self.pseudoseq_tensormap = {k: encode(v, 34, encoding, pad_scale).unsqueeze(0).flatten(start_dim=1) for k,v in PSEUDOSEQDICT.items()}\n",
    "        # kmer_time = dt.now()\n",
    "        self.y = y.contiguous()\n",
    "        self.x_features = torch.empty((len(x),))\n",
    "        # Add extra features\n",
    "        if len(feature_cols) > 0:\n",
    "            # TODO: When you add more features you need to concatenate to x_pseudosequence and save it to self.x_features\n",
    "            # these are NUMERICAL FEATURES like %Rank, expression, etc. of shape (N, len(feature_cols))\n",
    "            # x_features = torch.from_numpy(df[feature_cols].values).float()\n",
    "\n",
    "            self.extra_features_flag = True\n",
    "        else:\n",
    "            self.extra_features_flag = False\n",
    "\n",
    "        #  TODO dictmap for 9mer look-up and see if how many duplicated and can we save memory\n",
    "        #\n",
    "        if add_pseudo_sequence:\n",
    "            self.hla_tag = df['HLA'].values\n",
    "            self.extra_features_flag = True\n",
    "            # ps_time = dt.now()\n",
    "        if add_pfr:\n",
    "            x_pfr = PFR_calculation(df[seq_col], self.x_mask, max_len, window_size)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_pfr], dim=2)\n",
    "            # pfr_time = dt.now()\n",
    "        if add_fr_len:\n",
    "            x_fr_len = FR_lengths(self.x_mask, max_len, window_size)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_fr_len], dim=2)\n",
    "            # pfr_len_time = dt.now()\n",
    "        if add_pep_len:\n",
    "            x_pep_len = pep_len_1hot(df[seq_col], max_len, window_size, min_length=13, max_length=21)\n",
    "            self.x_tensor = torch.cat([self.x_tensor, x_pep_len], dim=2)\n",
    "            # peplen_time = dt.now()\n",
    "\n",
    "        # Saving df in case it's needed\n",
    "        self.df = df\n",
    "        self.len = len(x)\n",
    "        self.max_len = max_len\n",
    "        self.seq_col = seq_col\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns the appropriate input tensors (X, ..., y) depending on the bool flags\n",
    "        A bit convoluted return, but basically 4 conditions:\n",
    "            1. No burn-in, no extra features --> returns the normal x_tensor, kmers mask, target\n",
    "            2. Burn-in, no extra features --> returns the normal x_tensor, burn-in mask, target\n",
    "            3. No Burn-in, + extra features --> returns the normal x_tensor, kmers mask, x_features, target\n",
    "            4. Burn-in, + extra features --> returns the normal x_tensor, burn-in mask, x_features, target\n",
    "        :param idx:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.burn_in_flag:\n",
    "            if self.extra_features_flag:\n",
    "                x_pseudoseq = self.pseudoseq_tensormap[self.hlas[idx]]\n",
    "                return self.x_tensor[idx], self.burn_in_mask[idx], x_pseudoseq, self.y[idx]\n",
    "            else:\n",
    "                # 2\n",
    "                return self.x_tensor[idx], self.burn_in_mask[idx], self.y[idx]\n",
    "        else:\n",
    "            if self.extra_features_flag:\n",
    "                # 3\n",
    "                return self.x_tensor[idx], self.x_mask[idx], x_pseudoseq, self.y[idx]\n",
    "            else:\n",
    "                # 1\n",
    "                return self.x_tensor[idx], self.x_mask[idx], self.y[idx]\n",
    "\n",
    "    def burn_in(self, flag):\n",
    "        self.burn_in_flag = flag\n",
    "\n",
    "def _get_burnin_mask_batch(sequences, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_burnin_mask(x, max_len, motif_len, alphabet) for x in sequences])\n",
    "\n",
    "\n",
    "def _get_burnin_mask(seq, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    mask = torch.tensor([x in alphabet for i, x in enumerate(seq) if i < len(seq) - motif_len + 1]).float()\n",
    "    return F.pad(mask, (0, (max_len - motif_len + 1) - len(mask)), 'constant', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "79c639bc-e8db-4938-b871-e7d54fd58ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = TestDataset(sample, 13, 9, 'BL50LO', pad_scale=-20, add_pseudo_sequence=True, indel=True)\n",
    "testloader = dataset.get_dataloader(50, SequentialSampler)\n",
    "for batch in testloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a7ae09da-7523-4a51-8d6f-3337d923ec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch[0]==batch_normal[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "eaace935-6295-4677-86ed-0383ca45d250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch[2]==batch_normal[2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "58991f07-1626-4dd3-85d6-4fc4f2601095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 15, 180]),\n",
       " torch.Size([50, 15, 1]),\n",
       " torch.Size([50, 680]),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045d2f3-9d73-4ba3-ba07-adc12b6f2bcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# what the init code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b8f3beb2-aa30-4306-8061-2d5b9a40c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import NNAlignDatasetEFSinglePass, PseudoOTFDataset\n",
    "from src.models import NNAlignEFSinglePass\n",
    "from src.utils import get_class_initcode_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1629d037-631e-435f-956c-4539ca4dba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_len']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {'max_len':13}\n",
    "get_class_initcode_keys(PseudoOTFDataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4583e92f-f9a8-4733-a29b-ac00d9a5c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets failed: Traceback (most recent call last):\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/riwa/opt/anaconda3/envs/pynn/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 3\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# stupid init code name changes if we profile it ; Need a UglyWorkAround class to get the same init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f26df464-d32b-4bc8-a4dc-bbf58823186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self',\n",
       " 'df',\n",
       " 'max_len',\n",
       " 'window_size',\n",
       " 'encoding',\n",
       " 'seq_col',\n",
       " 'target_col',\n",
       " 'pad_scale',\n",
       " 'indel',\n",
       " 'burnin_alphabet',\n",
       " 'feature_cols',\n",
       " 'add_pseudo_sequence',\n",
       " 'pseudo_seq_col',\n",
       " 'add_pfr',\n",
       " 'add_fr_len',\n",
       " 'add_pep_len',\n",
       " 'add_z',\n",
       " 'matrix_dim',\n",
       " 'x',\n",
       " 'y',\n",
       " 'len_mask',\n",
       " 'x_mask',\n",
       " 'range_tensor',\n",
       " 'x_indel',\n",
       " 'indel_mask',\n",
       " 'x_pfr',\n",
       " 'x_fr_len',\n",
       " 'x_pep_len')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PseudoOTFDataset.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "173fb13f-18f5-4ff8-8502-d54b6f0134bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('args', 'kwargs', 'prof', 'val')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignDatasetEFSinglePass.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3095cf8d-e92d-41a1-af00-20821f8fc925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x95\\x03\\x97\\x00\\x02\\x00\\x89\\x05\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x02\\x02\\x00\\x02\\x00|\\x02\\x89\\x04\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00i\\x00|\\x01\\xa4\\x01\\x8e\\x01}\\x03\\x02\\x00\\x89\\x06|\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00|\\x03S\\x00'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignDatasetEFSinglePass.__init__.__code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "680e247c-c46e-459a-bc6a-dc5a376f2709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self',\n",
       " 'n_hidden',\n",
       " 'n_hidden_2',\n",
       " 'window_size',\n",
       " 'activation',\n",
       " 'extrafeat_dim',\n",
       " 'batchnorm',\n",
       " 'dropout',\n",
       " 'standardize',\n",
       " 'add_hidden_layer')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNAlignEFSinglePass.__init__.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2229599-0dd8-40d7-ba55-7426eaf8e434",
   "metadata": {},
   "source": [
    "# burn_in mask need to match indel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "96641b69-49e0-4c7a-a017-15a5ef4cefbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARNDCQEGHILKMFPSTWYV'"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(AA_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "282df748-abe2-45ff-86cf-9d1480739cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_burnin_mask_batch(sequences, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_burnin_mask(x, max_len, motif_len, alphabet) for x in sequences])\n",
    "\n",
    "\n",
    "def _get_burnin_mask(seq, max_len, motif_len, alphabet='ILVMFYW'):\n",
    "    mask = torch.tensor([x in alphabet for i, x in enumerate(seq) if i < len(seq) - motif_len + 1]).float()\n",
    "    return F.pad(mask, (0, (max_len - motif_len + 1) - len(mask)), 'constant', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "db43ff45-5098-4821-97dd-b11be9b1c01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_burnin_mask_batch(sample['sequence'].head(15), 13, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "08b96f39-8e6c-4411-8766-cc40f31c9c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELEMIKKKHLV'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6a25482b-0a89-4ee4-8ad5-354cc4e6dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QMEARQKECGA'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "04c00d45-5c28-4ea0-beac-016ebfea6a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RQLASEGLPAL'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b8e64c72-907c-4ec8-bfb9-1c87da1f660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FLQLMIDSQ'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "57657e96-b622-4670-afae-6342b6b22a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADNIYIFLEL'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['sequence'].head(15).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "53508ea8-1586-484d-a1d7-b60c7e3a403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VELEMIKKKHL 11\n",
      "['LEMIKKKHL', 'VEMIKKKHL', 'VEMIKKKHL', 'VELIKKKHL', 'VELEKKKHL', 'VELEMKKHL', 'VELEMIKHL', 'VELEMIKHL', 'VELEMIKKL', 'VELEMIKKK']\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "seq='VELEMIKKKHL'\n",
    "indel_windows = get_indel_windows(seq, 9)\n",
    "indel_burnin_mask = torch.tensor([x[0] in alphabet for x in indel_windows]).float()\n",
    "print(seq, len(seq))\n",
    "print(indel_windows)\n",
    "print(indel_burnin_mask, indel_burnin_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "80f4c1fd-daf5-4a99-9d94-b5189bc19af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_indel_burnin_mask(seq, window_size, alphabet='ILVMFYW'):\n",
    "    indel_windows = get_indel_windows(seq, window_size)\n",
    "    return torch.tensor([x[0] in alphabet for x in indel_windows]).float()\n",
    "\n",
    "def _get_indel_burnin_mask_batch(sequences, window_size, alphabet='ILVMFYW'):\n",
    "    return torch.stack([_get_indel_burnin_mask(x, window_size, alphabet) for x in sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f43c42fd-590b-4379-ae4b-0987cb81e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_burnin_mask = _get_indel_burnin_mask_batch(sample['sequence'], 9).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2baa9804-6c76-4ad7-89a0-c55a8dcd3b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10, 1])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indel_burnin_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f21b0025-8b0b-44d6-9d26-f3f904b01d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 5, 1])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.burn_in_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ab93a18d-1dc2-49cd-ab76-a05dc1b8d438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 15, 1])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([dataset.burn_in_mask, indel_burnin_mask], dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c8d33-596a-4dcf-8f25-32e833b8aa64",
   "metadata": {},
   "source": [
    "# Other stuff could be done on the fly (try to save as little as possible in memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
