{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee196b6-9d4c-4581-8c4d-49d39f386831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACoAAAAuCAYAAABeUotNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACXElEQVR4nO2WQUrrUBSG/4ZCoW1iSLVIkdBBAx1kCQEX0ImgoMsQHAbp3IkrcJCZIELpuIXuQ0vNSKOI3CSVSMXj5DWQUmrPI6m8Rz7I4B6Sky83Nzd/gYgI/wDSbwusSy6aNrlo2uSiaZOLps1fi768vKDVamE0GqWoswJi4nkeWZZFkiQRADo8PKTZbMZtw4Yt2m63qVwuk+M4BICazSZdXFxk4ZagQLR+KLm/v4dhGHBdF7quo1Ao4Pz8HI7jwHXdxLm+78P3/Xj89fWF6XQKWZbRaDQgScxVx3mqXq9HmqbFYwB0dXVFAOjt7S1x7v7+PgFYeozHY/aMFjkPFQQBKpVKolYqlQAAYRhCVdW43u/3EzMqhIBpmgAATdN4swmAJVqpVPD+/p6ofXx8AABkWU7UFUWBoiiJ8Rz2awdzezJNE6+vr/A8L649PDxgb28PW1tb7Juz4K4Vy7Lo5OSEfN+Pv/put/vjdUKIeI0KIdhrlC369PRER0dHVKvVaGdnh87Ozujz8/PH66IoItu2ybZtiqKILcrann6T//9fv2ly0bTZiOjz8zMODg6gqio0TYOqqhgOh6weGxE9Pj5GtVrF7e0tZFmGEAI3Nze8JuwNjcnd3R0BoMvLS9J1na6vrwkA1et1Vp/MReeJ6/HxMQ7Y+POHWkxcq8j81c8T1+7uLorFZAYKw3DtPpmLLktccxYT1yoyF12WuABge3ublbgyFzUMA5Zl4fT0FEEQYDKZAAA6nQ6vUUbfUILFxAWABoMBq0eentImF02bXDRtctG0yUXTJhdNm2/tMzRBDgOZWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1x1 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "f,a = plt.subplots(1,1,figsize=(1e-2, 1e-2))\n",
    "mpl.rcParams['figure.dpi'] = 180\n",
    "sns.set_style('darkgrid')\n",
    "import os,sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "# Here you import other functions and classes\n",
    "from src.utils import mkdirs, convert_path, pkl_dump, pkl_load, display_side, add_median_labels, get_palette\n",
    "from src.data_processing import encode_batch, AA_KEYS, BL62_VALUES, BL62FREQ_VALUES, HLAS, BL50, BL50_VALUES\n",
    "from src.models import NNAlignEFSinglePass\n",
    "from src.datasets import NNAlignDatasetEFSinglePass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f8cc00-3d23-44c9-89f9-dec0d0767b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>pseudoseq</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELLKHQRMHTGHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "      <td>DRQELLGHLPFD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KKDINNIVKTL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B15:01</td>\n",
       "      <td>DIRKKDKTLHEW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QVNGEAGSYEM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H-2-Dq</td>\n",
       "      <td>RKSQVNYEMTNQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DVGELVGLGDVM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H-2-Kb</td>\n",
       "      <td>CAVDVGDVMDAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENPVVPIGCL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-B51:01</td>\n",
       "      <td>RKTRENGCLATA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence  target         HLA     pseudoseq  partition\n",
       "0  ELLKHQRMHTGHL     0.0  HLA-A01:01  DRQELLGHLPFD          0\n",
       "1    KKDINNIVKTL     0.0  HLA-B15:01  DIRKKDKTLHEW          0\n",
       "2    QVNGEAGSYEM     0.0      H-2-Dq  RKSQVNYEMTNQ          0\n",
       "3   DVGELVGLGDVM     0.0      H-2-Kb  CAVDVGDVMDAL          0\n",
       "4    RENPVVPIGCL     0.0  HLA-B51:01  RKTRENGCLATA          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note : I always name my notebooks with the day's date, with YYMMDD_descriptor.ipynb, and data / output the same way\n",
    "\n",
    "\n",
    "# Here, a sample data just so that you can try playing around with the functions (that will have different columns from what you might have at the end)\n",
    "df = pd.read_csv('../data/mhc1_el_sub10k/mhc1_el_subsampled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d44346a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'R',\n",
       " 'N',\n",
       " 'D',\n",
       " 'C',\n",
       " 'Q',\n",
       " 'E',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'L',\n",
       " 'K',\n",
       " 'M',\n",
       " 'F',\n",
       " 'P',\n",
       " 'S',\n",
       " 'T',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'V']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processing import AA_KEYS\n",
    "\n",
    "AA_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7b317255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>pseudoseq</th>\n",
       "      <th>partition</th>\n",
       "      <th>len</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19510</th>\n",
       "      <td>ALLQASUYL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A02:01</td>\n",
       "      <td>TVVALLUYLCIL</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49766</th>\n",
       "      <td>AUGYKPKYLQL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H-2-Db</td>\n",
       "      <td>YCGAUGLQLKEK</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence  target         HLA     pseudoseq  partition  len  flag\n",
       "19510    ALLQASUYL     0.0  HLA-A02:01  TVVALLUYLCIL          1    9  True\n",
       "49766  AUGYKPKYLQL     0.0      H-2-Db  YCGAUGLQLKEK          4   11  True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flag'] = df['sequence'].apply(lambda x: any([z not in AA_KEYS for z in x]))\n",
    "df.query('flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24252db-b35d-401a-9341-d7457bcc354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, you can define the length of each sequence\n",
    "df['len'] = df['sequence'].apply(len)\n",
    "max_len = 13\n",
    "window_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4caaadf2-6120-4a19-bbe1-42a65c802f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,\n",
       "           -2.,  -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "         [ -1.,  -4.,  -3.,  -4.,  -2.,  -3.,  -4.,  -4.,  -4.,   5.,   2.,\n",
       "           -3.,   2.,   0.,  -3.,  -3.,  -1.,  -3.,  -1.,   4.],\n",
       "         [ -2.,  -3.,  -4.,  -4.,  -2.,  -2.,  -3.,  -4.,  -3.,   2.,   5.,\n",
       "           -3.,   3.,   1.,  -4.,  -3.,  -1.,  -2.,  -1.,   1.],\n",
       "         [  0.,  -3.,   0.,  -1.,  -3.,  -2.,  -3.,   8.,  -2.,  -4.,  -4.,\n",
       "           -2.,  -3.,  -4.,  -2.,   0.,  -2.,  -3.,  -3.,  -4.],\n",
       "         [ -3.,  -3.,  -4.,  -5.,  -2.,  -4.,  -3.,  -4.,  -1.,   0.,   1.,\n",
       "           -4.,   0.,   8.,  -4.,  -3.,  -2.,   1.,   4.,  -1.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [ -3.,  -3.,  -4.,  -5.,  -2.,  -4.,  -3.,  -4.,  -1.,   0.,   1.,\n",
       "           -4.,   0.,   8.,  -4.,  -3.,  -2.,   1.,   4.,  -1.],\n",
       "         [  0.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -2.,  -2.,  -1.,  -1.,\n",
       "           -1.,  -1.,  -2.,  -1.,   2.,   5.,  -3.,  -2.,   0.],\n",
       "         [ -2.,  -3.,  -4.,  -4.,  -2.,  -2.,  -3.,  -4.,  -3.,   2.,   5.,\n",
       "           -3.,   3.,   1.,  -4.,  -3.,  -1.,  -2.,  -1.,   1.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "          -20., -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "          -20., -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "          -20., -20., -20., -20., -20., -20., -20., -20., -20.],\n",
       "         [-20., -20., -20., -20., -20., -20., -20., -20., -20., -20., -20.,\n",
       "          -20., -20., -20., -20., -20., -20., -20., -20., -20.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we can use \"-\" as the insert, with put 0s (though it is not the most correct technically)\n",
    "encode_batch(['GILGF-FTL'], max_len=13, encoding='BL50LO', pad_scale=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34560919-3433-4ebd-bd59-af7c8d5ed191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-GILGFVTL', 'G-ILGFVTL', 'GI-LGFVTL', 'GIL-GFVTL', 'GILG-FVTL', 'GILGF-VTL', 'GILGFV-TL', 'GILGFVT-L', 'GILGFVTL-', '---------']\n",
      "['GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', 'GILGFVTLI', '---------']\n",
      "['ILGFVTLIG', 'GLGFVTLIG', 'GIGFVTLIG', 'GILFVTLIG', 'GILGVTLIG', 'GILGFTLIG', 'GILGFVLIG', 'GILGFVTIG', 'GILGFVTLG', 'GILGFVTLI']\n",
      "['LGFVTLIGF', 'GGFVTLIGF', 'GIFVTLIGF', 'GILVTLIGF', 'GILGTLIGF', 'GILGFLIGF', 'GILGFVIGF', 'GILGFVTGF', 'GILGFVTLF', 'GILGFVTLI']\n",
      "['GFVTLIGFT', 'GFVTLIGFT', 'GIVTLIGFT', 'GILTLIGFT', 'GILGLIGFT', 'GILGFIGFT', 'GILGFVGFT', 'GILGFVTFT', 'GILGFVTLT', 'GILGFVTLI']\n",
      "['FVTLIGFTE', 'GVTLIGFTE', 'GITLIGFTE', 'GILLIGFTE', 'GILGIGFTE', 'GILGFGFTE', 'GILGFVFTE', 'GILGFVTTE', 'GILGFVTLE', 'GILGFVTLI']\n",
      "torch.Size([6, 10, 13, 20])\n"
     ]
    }
   ],
   "source": [
    "from src.data_processing import encode, encode_batch\n",
    "def do_insertion_deletion(sequence, max_len=13, encoding='BL50LO', pad_scale=-20, window_size=9):\n",
    "    length = len(sequence)\n",
    "    indel_windows = []\n",
    "\n",
    "    # Insertion for sequences shorter than the window size\n",
    "    if length < window_size:\n",
    "        for i in range(window_size):\n",
    "            indel_windows.append(sequence[:i] + '-' + sequence[i:])\n",
    "        indel_windows.append('-'*9)    \n",
    "    # Replicate sequence for sequences equal to the window size\n",
    "    elif length == window_size:\n",
    "        indel_windows = [sequence for _ in range(window_size)]\n",
    "        indel_windows.append('-'*9) \n",
    "    # Deletion for sequences longer than the window size\n",
    "    else:\n",
    "        del_len = length - window_size\n",
    "        for i in range(length - del_len + 1):\n",
    "            indel_windows.append(sequence[:i] + sequence[i+del_len:])\n",
    "            \n",
    "    # Encoding the sequences\n",
    "    encoded_sequences = encode_batch(indel_windows, max_len=max_len, encoding=encoding, pad_scale=pad_scale)\n",
    "    print(indel_windows)\n",
    "    return encoded_sequences\n",
    "    \n",
    "def batch_insertion_deletion(sequences, max_len=13, encoding='BL50LO', pad_scale=-20, window_size=9):\n",
    "    # Process each sequence individually with do_insertion_deletion\n",
    "    processed_sequences = [do_insertion_deletion(seq, max_len=max_len, encoding=encoding, pad_scale=pad_scale, window_size=window_size) for seq in sequences]\n",
    "    \n",
    "    # Stack the processed sequences along a new dimension to maintain the N x 9 x 13 x 20 structure\n",
    "    # Ensure each do_insertion_deletion call returns a tensor of shape 9 x 13 x 20\n",
    "    indel_windows_batch = torch.stack(processed_sequences)\n",
    "    return indel_windows_batch\n",
    "    \n",
    "# Example usage:\n",
    "sequences = ['GILGFVTL', 'GILGFVTLI', 'GILGFVTLIG', 'GILGFVTLIGF', 'GILGFVTLIGFT', 'GILGFVTLIGFTE']\n",
    "results = batch_insertion_deletion(sequences, max_len = 13)\n",
    "\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dc36975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>HLA</th>\n",
       "      <th>pseudoseq</th>\n",
       "      <th>partition</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELLKHQRMHTGHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "      <td>DRQELLGHLPFD</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence  target         HLA     pseudoseq  partition  len\n",
       "0  ELLKHQRMHTGHL     0.0  HLA-A01:01  DRQELLGHLPFD          0   13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d55cd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=13\n",
    "window_size=9\n",
    "x = encode_batch(sequences, max_len, 'BL50LO', -20)\n",
    "\n",
    "# Creating the mask to allow selection of kmers without padding\n",
    "x_mask = torch.from_numpy(np.array([len(x) for x in sequences])) - window_size\n",
    "range_tensor = torch.arange(max_len - window_size + 1).unsqueeze(0).repeat(len(x), 1)\n",
    "# Mask for Kmers + padding\n",
    "x_mask = (range_tensor <= x_mask.unsqueeze(1)).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "042f0be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 5, 9, 20]), torch.Size([6, 5, 180]), torch.Size([6, 5, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = x.unfold(1, window_size, 1).transpose(2, 3) \\\n",
    "            .reshape(len(x), max_len - window_size + 1, window_size, 20)\n",
    "x_flat = x_tensor.flatten(2, 3).contiguous()\n",
    "x_tensor.shape, x_flat.shape, x_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cec6cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indel_mask(length, window_size):\n",
    "    mask = torch.zeros(1, window_size+1, 1)\n",
    "    if length<window_size:\n",
    "        mask[:, :-1, :].fill_(1)\n",
    "    elif length==window_size:\n",
    "        # Actually shouldn't fill with 1 because we are concatenating to the other mask\n",
    "        # and only a single window (i.e. the first, un-concatenated one) is the correct one\n",
    "        # mask[:, :1, :].fill_(1)\n",
    "        pass\n",
    "    elif length>window_size:\n",
    "        mask.fill_(1)\n",
    "    return mask\n",
    "\n",
    "def batch_indel_mask(lengths, window_size):\n",
    "    return torch.cat([create_indel_mask(length, window_size) for length in lengths], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b1901b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing pad from the indel results\n",
    "results = results[:,:,:window_size,:]\n",
    "# Creating the mask\n",
    "len_mask = [len(x) for x in sequences]\n",
    "indel_mask = batch_indel_mask(len_mask, window_size)\n",
    "indel_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "76cf688f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 10, 9, 20]),\n",
       " torch.Size([6, 5, 9, 20]),\n",
       " torch.Size([6, 10, 180]),\n",
       " torch.Size([6, 5, 180]),\n",
       " torch.Size([6, 15, 9, 20]),\n",
       " torch.Size([6, 15, 180]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should concatenate results (x_indels) to x_tensor before flattening ?\n",
    "# Also concatenate the indel_mask to x_mask the same way\n",
    "results.shape, x_tensor.shape, results.flatten(2,3).shape, x_tensor.flatten(2,3).shape, torch.cat([x_tensor, results], axis=1).shape, torch.cat([x_tensor, results], axis=1).flatten(2,3).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pynn] *",
   "language": "python",
   "name": "conda-env-pynn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
